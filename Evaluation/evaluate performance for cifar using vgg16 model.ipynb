{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e05827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb10fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfa00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de763f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = VGG('VGG11')\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8057db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_model(path):\n",
    "    model = VGG('VGG16')\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0069b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"cifar10_vgg16_model_final.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752d244c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_cifar_model(path)\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee15fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "train_loader_cifar = DataLoader(trainset, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b676974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d625692b",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75fba59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_benign(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for benign\")\n",
    "    \n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['b_images']\n",
    "    adaptive_label = npobj['b_labels']\n",
    "    \n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Benign.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6edd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_adv(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for adv\")\n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['a_images']\n",
    "    adaptive_label = npobj['a_labels']\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.10)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Adv.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "993dd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "777cf444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "544dc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7015a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_auc(adv_path, model):\n",
    "    #logitgaussian3\n",
    "    k=[3,7,11,15, 20, 22, 25, 28, 30, 35, 37]\n",
    "    l=[38,38,38,38,38,38,38,38,38,38, 38]\n",
    "\n",
    "    m=[500,520,530, 600, 750, 700,800, 900, 1000, 1300, 1600]\n",
    "    n=[1950,1950,1950,1950,1950,1950,1950,1950,1950,1950, 1950]\n",
    "\n",
    "    compute_metrics_benign(adv_path, model)\n",
    "    compute_metrics_adv(adv_path, model)\n",
    "    df_cifar = pd.read_csv(\"adaptive_Benign.csv\")\n",
    "    attr_gaussian3 = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3 = df_cifar.iloc[5].values.flatten().tolist()[1:]\n",
    "        \n",
    "    fpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "        fpr_results.append(FPR/100)\n",
    "        \n",
    "    df_pgd_eps1 = pd.read_csv(\"adaptive_Adv.csv\")\n",
    "    attr_gaussian3_eps1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3_eps1 = df_pgd_eps1.iloc[5].values.flatten().tolist()[1:]\n",
    "    \n",
    "    tpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return(sklearn.metrics.auc(fpr_results, tpr_results), fpr_results, tpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95e55530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "adv_path1 = 'adv samples/FGSM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/FGSM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/FGSM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/FGSM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60847221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6166820000000002,\n",
       " [0.044,\n",
       "  0.063,\n",
       "  0.109,\n",
       "  0.17,\n",
       "  0.39,\n",
       "  0.431,\n",
       "  0.637,\n",
       "  0.81,\n",
       "  0.895,\n",
       "  0.9940000000000001,\n",
       "  1.0],\n",
       " [0.135,\n",
       "  0.16,\n",
       "  0.207,\n",
       "  0.325,\n",
       "  0.568,\n",
       "  0.605,\n",
       "  0.7760000000000001,\n",
       "  0.894,\n",
       "  0.944,\n",
       "  0.998,\n",
       "  1.0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6a74d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.7018224999999999, [0.033, 0.05800000000000001, 0.113, 0.193, 0.38299999999999995, 0.417, 0.611, 0.791, 0.8809999999999999, 0.988, 1.0], [0.12, 0.153, 0.21600000000000003, 0.387, 0.703, 0.7559999999999999, 0.903, 0.968, 0.9890000000000001, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.865714, [0.035, 0.063, 0.10100000000000002, 0.185, 0.405, 0.435, 0.637, 0.813, 0.91, 0.996, 1.0], [0.152, 0.271, 0.559, 0.81, 0.964, 0.98, 0.996, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9360025000000001, [0.046, 0.066, 0.114, 0.187, 0.3990000000000001, 0.42699999999999994, 0.636, 0.8169999999999998, 0.889, 0.995, 1.0], [0.614, 0.7559999999999999, 0.927, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19057576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGD\n",
    "adv_path1 = 'adv samples/PGD/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/PGD/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/PGD/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/PGD/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d51a2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6020519999999999,\n",
       " [0.031,\n",
       "  0.043,\n",
       "  0.088,\n",
       "  0.169,\n",
       "  0.377,\n",
       "  0.418,\n",
       "  0.636,\n",
       "  0.823,\n",
       "  0.9060000000000001,\n",
       "  0.998,\n",
       "  1.0],\n",
       " [0.15,\n",
       "  0.184,\n",
       "  0.226,\n",
       "  0.3390000000000001,\n",
       "  0.549,\n",
       "  0.557,\n",
       "  0.727,\n",
       "  0.862,\n",
       "  0.924,\n",
       "  0.995,\n",
       "  1.0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ff45a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.6014479999999999, [0.043, 0.069, 0.114, 0.192, 0.387, 0.425, 0.612, 0.799, 0.895, 0.991, 1.0], [0.117, 0.145, 0.195, 0.303, 0.529, 0.573, 0.7559999999999999, 0.888, 0.955, 0.993, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.7253850000000001, [0.045, 0.078, 0.12300000000000001, 0.19699999999999998, 0.413, 0.458, 0.638, 0.82, 0.905, 0.993, 0.9990000000000001], [0.08900000000000001, 0.137, 0.269, 0.465, 0.759, 0.841, 0.956, 0.9890000000000001, 0.9990000000000001, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.898431, [0.038, 0.059, 0.102, 0.174, 0.379, 0.43200000000000005, 0.615, 0.782, 0.897, 0.995, 1.0], [0.234, 0.41, 0.679, 0.887, 0.9890000000000001, 0.992, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9273c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIM\n",
    "adv_path1 = 'adv samples/BIM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/BIM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/BIM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/BIM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c67e5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5776094999999999,\n",
       " [0.035,\n",
       "  0.049,\n",
       "  0.094,\n",
       "  0.165,\n",
       "  0.374,\n",
       "  0.41600000000000004,\n",
       "  0.609,\n",
       "  0.813,\n",
       "  0.9010000000000001,\n",
       "  0.998,\n",
       "  1.0],\n",
       " [0.134,\n",
       "  0.157,\n",
       "  0.196,\n",
       "  0.289,\n",
       "  0.512,\n",
       "  0.534,\n",
       "  0.696,\n",
       "  0.825,\n",
       "  0.9129999999999999,\n",
       "  0.993,\n",
       "  0.9990000000000001])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79a1ae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.581305, [0.043, 0.068, 0.11200000000000002, 0.175, 0.369, 0.43, 0.626, 0.8030000000000002, 0.889, 0.993, 1.0], [0.117, 0.15, 0.18899999999999997, 0.293, 0.509, 0.54, 0.716, 0.858, 0.922, 0.9940000000000001, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.5981124999999999, [0.04100000000000001, 0.067, 0.113, 0.204, 0.403, 0.441, 0.631, 0.805, 0.909, 0.993, 1.0], [0.117, 0.151, 0.204, 0.307, 0.538, 0.61, 0.7659999999999999, 0.8809999999999999, 0.9419999999999998, 0.9990000000000001, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.683261, [0.035, 0.05600000000000001, 0.111, 0.169, 0.395, 0.424, 0.604, 0.7929999999999999, 0.8909999999999999, 0.991, 1.0], [0.066, 0.096, 0.163, 0.332, 0.661, 0.758, 0.893, 0.961, 0.9840000000000001, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7f937f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CW\n",
    "adv_path1 = 'adv samples/CW/0.15eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a95a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7991775000000001,\n",
       " [0.037,\n",
       "  0.073,\n",
       "  0.12300000000000001,\n",
       "  0.18600000000000003,\n",
       "  0.407,\n",
       "  0.44299999999999995,\n",
       "  0.619,\n",
       "  0.805,\n",
       "  0.8909999999999999,\n",
       "  0.99,\n",
       "  0.9990000000000001],\n",
       " [0.18600000000000003,\n",
       "  0.262,\n",
       "  0.395,\n",
       "  0.612,\n",
       "  0.878,\n",
       "  0.922,\n",
       "  0.983,\n",
       "  0.9990000000000001,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
