{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1154ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9015c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6288cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6e8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = '/home/db1702/Downloads/imagenet-mini/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d45233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_model():\n",
    "    model = models.resnet50(pretrained=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc077361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ef0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "test = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "test_loader = DataLoader(test, shuffle=True, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854473a4",
   "metadata": {},
   "source": [
    "# For given adversarial images and benign images, collect metrics of feature attribution sensitivity and model prediction sensitivity. Save in csv that will be used for inspecting detection performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4cc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d271c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50304a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uniform noise function\n",
    "def add_uniform_noise(image):\n",
    "    # Generate uniform noise with mean 0 and standard deviation 25\n",
    "    noise = np.random.uniform(low=-0.5, high=0.5, size=image.shape).astype(np.float32)\n",
    "    noisy_image = np.clip(image + noise, 0, 1).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def uniform_noise(x_batch, y_batch): \n",
    "    # Convert batch of images to numpy array\n",
    "    images = x_batch.detach().cpu().numpy().transpose(0, 2, 3, 1) * 1.0\n",
    "    # Add Poisson noise to each image in the batch\n",
    "    noisy_images = [add_uniform_noise(image) for image in images]\n",
    "    # Convert noisy images back to Tensor format\n",
    "    noisy_inputs = torch.from_numpy(np.array(noisy_images).transpose(0, 3, 1, 2) / 1.0).float()\n",
    "    return noisy_inputs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a21aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_benign(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for benign\")\n",
    "    \n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['b_images']\n",
    "    adaptive_label = npobj['b_labels']\n",
    "    \n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.25)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.35)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "        attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "        logit_uniform\n",
    "    ], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\",\n",
    "        \"uniform attr\",\n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "        \"uniform logit\"\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Benign.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77980925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_adv(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for adv\")\n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['a_images']\n",
    "    adaptive_label = npobj['a_labels']\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.25)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.35)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "        attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "    logit_uniform], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\",\n",
    "        \"uniform attr\",\n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "        \"uniform logit\"\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Adv.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4c3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed11de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc203be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f6b6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_auc(adv_path, model):\n",
    "    #logitgaussian3\n",
    "#     k=[1810,2510,2810,3000, 3200,3500, 6000]\n",
    "#     l=[6700,6700,6700,6700,6700,6700, 6700]\n",
    "    \n",
    "    k=[1023, 1300,1490,1580, 1600, 1700, 1800, 1900, 2100]\n",
    "    l=[2970, 2970,2970,2970, 2970, 2970, 2970, 2970, 2970]\n",
    "    \n",
    "    m=[1340, 1900, 2200, 2400,  2800, 3000, 3400, 5000,7000 ]\n",
    "    n=[10894, 10894, 10894,10894,10894,10894, 10894, 10894, 10894]\n",
    "\n",
    "    \n",
    "    #attrgaussian3\n",
    "#     m=[1400,1750,1900, 2300, 3200, 3500, 6000]\n",
    "#     n=[6600,6600,6600,6600,6600,6600,6600]\n",
    "\n",
    "    \n",
    "    compute_metrics_benign(adv_path, model)\n",
    "    compute_metrics_adv(adv_path, model)\n",
    "    df_cifar = pd.read_csv(\"adaptive_Benign.csv\")\n",
    "    attr_gaussian3 = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3 = df_cifar.iloc[6].values.flatten().tolist()[1:]\n",
    "        \n",
    "    fpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "        fpr_results.append(FPR/100)\n",
    "        \n",
    "    df_pgd_eps1 = pd.read_csv(\"adaptive_Adv.csv\")\n",
    "    attr_gaussian3_eps1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3_eps1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "    \n",
    "    tpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return(sklearn.metrics.auc(fpr_results, tpr_results), tpr_results, fpr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03417962",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aec736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adv_path1 = 'adv samples/IMAGENET/ResNet50/FGSM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/ResNet50/FGSM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/ResNet50/FGSM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/ResNet50/FGSM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a37e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6485255,\n",
       " [0.01, 0.09300000000000001, 0.281, 0.425, 0.545, 0.69, 0.847, 0.985, 1.0],\n",
       " [0.005, 0.044, 0.133, 0.215, 0.319, 0.462, 0.679, 0.93, 0.996])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c20c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.7535475, [0.01, 0.13, 0.3990000000000001, 0.584, 0.728, 0.858, 0.945, 0.998, 1.0], [0.001, 0.042, 0.127, 0.222, 0.32899999999999996, 0.46, 0.662, 0.929, 0.995])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.861404, [0.017, 0.282, 0.616, 0.787, 0.922, 0.9739999999999999, 0.996, 1.0, 1.0], [0.002, 0.038, 0.121, 0.23200000000000004, 0.337, 0.46, 0.652, 0.931, 0.998])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9507700000000001, [0.087, 0.721, 0.926, 0.977, 0.998, 0.9990000000000001, 1.0, 1.0, 1.0], [0.004, 0.032, 0.132, 0.22, 0.325, 0.467, 0.664, 0.926, 0.995])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04ab3c",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1c116ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/ResNet50/PGD/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/ResNet50/PGD/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/ResNet50/PGD/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/ResNet50/PGD/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f6ccd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9840949999999999,\n",
       " [0.988, 0.988, 0.988, 0.988, 0.992, 0.992, 0.992, 0.996, 0.998],\n",
       " [0.004, 0.038, 0.124, 0.199, 0.297, 0.442, 0.626, 0.907, 0.996])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "127bd0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9890000000000001, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.005, 0.03, 0.11899999999999998, 0.226, 0.335, 0.47, 0.664, 0.938, 0.9940000000000001])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.994, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.003, 0.036, 0.131, 0.21899999999999997, 0.32, 0.465, 0.672, 0.9280000000000002, 0.997])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9849999999999999, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.01, 0.039, 0.127, 0.207, 0.331, 0.488, 0.675, 0.91, 0.995])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759050a",
   "metadata": {},
   "source": [
    "# BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9cb26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/ResNet50/BIM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/ResNet50/BIM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/ResNet50/BIM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/ResNet50/BIM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faea2b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3494965,\n",
       " [0.126, 0.154, 0.192, 0.22, 0.23799999999999996, 0.277, 0.345, 0.6, 0.873],\n",
       " [0.002, 0.036, 0.127, 0.205, 0.3, 0.42699999999999994, 0.625, 0.917, 0.997])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fbb9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.4697404999999999, [0.374, 0.379, 0.391, 0.4040000000000001, 0.41600000000000004, 0.442, 0.474, 0.613, 0.863], [0.004, 0.04100000000000001, 0.139, 0.24600000000000002, 0.32899999999999996, 0.482, 0.666, 0.9330000000000002, 0.996])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.5870895, [0.537, 0.539, 0.545, 0.551, 0.554, 0.563, 0.572, 0.682, 0.8539999999999999], [0.003, 0.037, 0.121, 0.22, 0.315, 0.447, 0.653, 0.93, 0.998])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.6162814999999999, [0.585, 0.586, 0.586, 0.588, 0.588, 0.588, 0.602, 0.715, 0.88], [0.002, 0.04, 0.135, 0.221, 0.299, 0.44299999999999995, 0.639, 0.921, 0.99])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bedf4",
   "metadata": {},
   "source": [
    "# CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67abd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/ResNet50/CW/0.15eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fd8e0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9513506559031282,\n",
       " [0.7214934409687185,\n",
       "  0.8718466195761857,\n",
       "  0.9445005045408678,\n",
       "  0.9616548940464178,\n",
       "  0.9656912209889001,\n",
       "  0.9778002018163471,\n",
       "  0.987891019172553,\n",
       "  0.9969727547931383,\n",
       "  0.9989909182643796],\n",
       " [0.006,\n",
       "  0.047,\n",
       "  0.138,\n",
       "  0.22699999999999998,\n",
       "  0.332,\n",
       "  0.45899999999999996,\n",
       "  0.644,\n",
       "  0.915,\n",
       "  0.991])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df0b02",
   "metadata": {},
   "source": [
    "# MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb9f79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mobilet model first\n",
    "\n",
    "def load_imagenet_model():\n",
    "    model=torchvision.models.mobilenet_v3_small(weights=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cb81e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c4fac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_auc(adv_path, model):\n",
    "    #logitgaussian3\n",
    "    k=[1710, 1810,2000, 2510,2810,3000, 3200,3500, 6000]\n",
    "    l=[6700, 6700,6700, 6700,6700,6700,6700,6700, 6700]\n",
    "    \n",
    "    #attrgaussian3\n",
    "    m=[1200, 1400, 1600, 1750,1900, 2300, 3200, 3500, 6000]\n",
    "    n=[6600, 6600,6600, 6600,6600,6600,6600,6600,6600]\n",
    "\n",
    "    \n",
    "    compute_metrics_benign(adv_path, model)\n",
    "    compute_metrics_adv(adv_path, model)\n",
    "    df_cifar = pd.read_csv(\"adaptive_Benign.csv\")\n",
    "    attr_gaussian3 = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3 = df_cifar.iloc[6].values.flatten().tolist()[1:]\n",
    "        \n",
    "    fpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "        fpr_results.append(FPR/100)\n",
    "        \n",
    "    df_pgd_eps1 = pd.read_csv(\"adaptive_Adv.csv\")\n",
    "    attr_gaussian3_eps1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3_eps1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "    \n",
    "    tpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return sklearn.metrics.auc(fpr_results, tpr_results), fpr_results, tpr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901cb3d",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "997fa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adv_path1 = 'adv samples/IMAGENET/MobileNet/FGSM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/MobileNet/FGSM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/MobileNet/FGSM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/MobileNet/FGSM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27c92494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8148525,\n",
       " [0.03, 0.06, 0.121, 0.207, 0.308, 0.542, 0.8809999999999999, 0.931, 1.0],\n",
       " [0.105, 0.262, 0.512, 0.704, 0.825, 0.948, 0.998, 1.0, 1.0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "810b5284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9126704999999999, [0.027000000000000003, 0.059, 0.124, 0.20800000000000002, 0.317, 0.559, 0.894, 0.949, 1.0], [0.276, 0.567, 0.815, 0.9230000000000002, 0.971, 0.995, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.960005, [0.031, 0.06, 0.11600000000000002, 0.21600000000000003, 0.313, 0.565, 0.885, 0.9330000000000002, 1.0], [0.762, 0.915, 0.98, 0.998, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.979014, [0.02, 0.057, 0.12, 0.18600000000000003, 0.287, 0.522, 0.8640000000000001, 0.916, 1.0], [0.961, 0.996, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab8271",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c177cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/MobileNet/PGD/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/MobileNet/PGD/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/MobileNet/PGD/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/MobileNet/PGD/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f1044d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9549650000000001,\n",
       " [0.039,\n",
       "  0.077,\n",
       "  0.148,\n",
       "  0.235,\n",
       "  0.32800000000000007,\n",
       "  0.568,\n",
       "  0.8740000000000001,\n",
       "  0.926,\n",
       "  1.0],\n",
       " [0.985, 0.987, 0.988, 0.99, 0.993, 0.995, 0.997, 0.998, 1.0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89aa5eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.959, [0.04100000000000001, 0.074, 0.14, 0.239, 0.32899999999999996, 0.538, 0.877, 0.929, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.969, [0.031, 0.063, 0.12, 0.221, 0.333, 0.561, 0.892, 0.938, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.965, [0.035, 0.069, 0.13, 0.228, 0.332, 0.579, 0.8759999999999999, 0.937, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064768a7",
   "metadata": {},
   "source": [
    "# BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdf0e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/MobileNet/BIM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/IMAGENET/MobileNet/BIM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/IMAGENET/MobileNet/BIM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/IMAGENET/MobileNet/BIM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ca5a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4813319999999999,\n",
       " [0.029000000000000005,\n",
       "  0.049,\n",
       "  0.11600000000000002,\n",
       "  0.212,\n",
       "  0.31,\n",
       "  0.53,\n",
       "  0.883,\n",
       "  0.94,\n",
       "  1.0],\n",
       " [0.272, 0.277, 0.288, 0.332, 0.363, 0.442, 0.728, 0.809, 0.9990000000000001])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a42443b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.6262220000000001, [0.031, 0.069, 0.131, 0.222, 0.331, 0.55, 0.882, 0.938, 1.0], [0.52, 0.522, 0.525, 0.542, 0.56, 0.621, 0.786, 0.839, 0.9990000000000001])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.763795, [0.034, 0.074, 0.139, 0.21899999999999997, 0.317, 0.531, 0.877, 0.9330000000000002, 1.0], [0.731, 0.731, 0.732, 0.737, 0.742, 0.762, 0.865, 0.905, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.8369044999999999, [0.024, 0.05800000000000001, 0.118, 0.217, 0.324, 0.55, 0.867, 0.932, 1.0], [0.802, 0.8030000000000002, 0.8030000000000002, 0.8080000000000002, 0.818, 0.845, 0.921, 0.9469999999999998, 0.9990000000000001])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6365f",
   "metadata": {},
   "source": [
    "# CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beb865bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8679844999999999,\n",
       " [0.032, 0.072, 0.129, 0.23, 0.33, 0.548, 0.882, 0.935, 1.0],\n",
       " [0.533,\n",
       "  0.572,\n",
       "  0.657,\n",
       "  0.861,\n",
       "  0.926,\n",
       "  0.9519999999999998,\n",
       "  0.982,\n",
       "  0.9940000000000001,\n",
       "  1.0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_path1 = 'adv samples/IMAGENET/MobileNet/CW/0.15eps.npz'\n",
    "\n",
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc032a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
