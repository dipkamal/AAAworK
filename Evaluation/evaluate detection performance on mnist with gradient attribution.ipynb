{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcdc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76958897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34baaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d99450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet_normal(torch.nn.Module):\n",
    "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163d7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_model(path):\n",
    "    model = LeNet_normal()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a66f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/Models/MNIST/mnist_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc947b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet_normal(\n",
       "  (conv_1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_2): ReLU()\n",
       "  (fc_1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu_4): ReLU()\n",
       "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_mnist_model(modelpath)\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca08572",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.MNIST(root='./sample_data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45294b0",
   "metadata": {},
   "source": [
    "# For given adversarial images and benign images, collect metrics of feature attribution sensitivity and model prediction sensitivity. Save in csv that will be used for inspecting detection performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414ac001",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/MNIST/FGSM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/MNIST/FGSM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/MNIST/FGSM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/MNIST/FGSM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "593a859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f81d1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4741377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_benign(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for benign\")\n",
    "    \n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['b_images']\n",
    "    adaptive_label = npobj['b_labels']\n",
    "    \n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Benign.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb31b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_adv(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for adv\")\n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['a_images']\n",
    "    adaptive_label = npobj['a_labels']\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.005)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.01)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.05)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"Saliency\", \"device\": device})\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\", \n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Adv.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63dd8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92e84cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cf55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a020fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_auc(adv_path, model):\n",
    "    #logitgaussian3\n",
    "    \n",
    "    k=[0.07,0.07,0.07,0.07, 0.07,0.07,0.07,0.07,0.07,0.07, 0.07]\n",
    "    l=[3.3,2.5,2.1,1.7,1.5, 1.3, 1.1, 0.7, 0.5, 0.3, 0.1]\n",
    "\n",
    "    #attr\n",
    "    m=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "    n=[250,200,150,120, 110, 100, 90, 80, 70, 30,10]\n",
    "\n",
    "    \n",
    "    compute_metrics_benign(adv_path, model)\n",
    "    compute_metrics_adv(adv_path, model)\n",
    "    df_cifar = pd.read_csv(\"adaptive_Benign.csv\")\n",
    "    attr_gaussian3 = df_cifar.iloc[0].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3 = df_cifar.iloc[3].values.flatten().tolist()[1:]\n",
    "        \n",
    "    fpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "        fpr_results.append(FPR/100)\n",
    "        \n",
    "    df_pgd_eps1 = pd.read_csv(\"adaptive_Adv.csv\")\n",
    "    attr_gaussian3_eps1 = df_pgd_eps1.iloc[0].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3_eps1 = df_pgd_eps1.iloc[3].values.flatten().tolist()[1:]\n",
    "    \n",
    "    tpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return sklearn.metrics.auc(fpr_results, tpr_results), fpr_results, tpr_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e08b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9675370000000001, [0.026000000000000002, 0.049, 0.095, 0.184, 0.237, 0.32, 0.397, 0.635, 0.802, 0.949, 0.9990000000000001], [0.902, 0.959, 0.985, 0.9940000000000001, 0.9940000000000001, 0.995, 0.997, 0.9990000000000001, 1.0, 1.0, 1.0])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path1, normal_model))\n",
    "print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9da37c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9789340000000001, [0.018, 0.04, 0.076, 0.166, 0.214, 0.282, 0.37, 0.612, 0.775, 0.944, 0.998], [0.966, 0.987, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9814570000000001, [0.017, 0.048, 0.103, 0.177, 0.23, 0.287, 0.377, 0.627, 0.794, 0.954, 0.9990000000000001], [0.983, 0.995, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9830000000000001, [0.017, 0.042, 0.083, 0.168, 0.228, 0.291, 0.38, 0.616, 0.7829999999999999, 0.9469999999999998, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path3, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218fec9",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2dada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/MNIST/PGD/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/MNIST/PGD/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/MNIST/PGD/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/MNIST/PGD/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77764df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9840000000000001,\n",
       " [0.016, 0.047, 0.103, 0.172, 0.226, 0.3, 0.396, 0.633, 0.789, 0.959, 1.0],\n",
       " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_auc(adv_path1, normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbeb8605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.978, [0.022, 0.052000000000000005, 0.099, 0.174, 0.22699999999999998, 0.31, 0.397, 0.629, 0.791, 0.956, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.976, [0.024, 0.049, 0.098, 0.18099999999999997, 0.23799999999999996, 0.307, 0.397, 0.63, 0.773, 0.949, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.969, [0.029000000000000005, 0.051, 0.091, 0.171, 0.218, 0.302, 0.403, 0.627, 0.789, 0.9519999999999998, 0.998], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path3, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3ebd9",
   "metadata": {},
   "source": [
    "# BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da70d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = 'adv samples/MNIST/BIM/0.03137254901960784eps.npz'\n",
    "adv_path2 = 'adv samples/MNIST/BIM/0.06274509803921569eps.npz'\n",
    "adv_path3 = 'adv samples/MNIST/BIM/0.12549019607843137eps.npz'\n",
    "adv_path4 = 'adv samples/MNIST/BIM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b45c37d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.57069,\n",
       " [0.022,\n",
       "  0.049,\n",
       "  0.10400000000000001,\n",
       "  0.17800000000000002,\n",
       "  0.23,\n",
       "  0.3,\n",
       "  0.37200000000000005,\n",
       "  0.624,\n",
       "  0.785,\n",
       "  0.959,\n",
       "  1.0],\n",
       " [0.038, 0.078, 0.143, 0.24, 0.31, 0.389, 0.489, 0.714, 0.865, 0.968, 1.0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_auc(adv_path1, normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8804d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.5509325000000002, [0.019, 0.045, 0.092, 0.156, 0.203, 0.27, 0.363, 0.613, 0.7879999999999999, 0.945, 0.9990000000000001], [0.027000000000000003, 0.063, 0.11600000000000002, 0.22, 0.279, 0.35600000000000004, 0.449, 0.666, 0.8269999999999998, 0.971, 1.0])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.5161410000000001, [0.02, 0.04100000000000001, 0.09, 0.17800000000000002, 0.228, 0.289, 0.37799999999999995, 0.624, 0.77, 0.936, 0.9990000000000001], [0.042, 0.08200000000000002, 0.141, 0.207, 0.26, 0.33, 0.413, 0.619, 0.774, 0.935, 0.997])\n",
      "---\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.5319345, [0.025, 0.049, 0.10100000000000002, 0.182, 0.231, 0.295, 0.391, 0.628, 0.7760000000000001, 0.9419999999999998, 1.0], [0.051, 0.085, 0.132, 0.221, 0.276, 0.355, 0.44800000000000006, 0.655, 0.797, 0.948, 0.9990000000000001])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path3, normal_model))\n",
    "print('---')\n",
    "print( return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb23be",
   "metadata": {},
   "source": [
    "# CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "823f1483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3929875000000001,\n",
       " [0.024,\n",
       "  0.05,\n",
       "  0.086,\n",
       "  0.179,\n",
       "  0.23,\n",
       "  0.296,\n",
       "  0.384,\n",
       "  0.628,\n",
       "  0.7829999999999999,\n",
       "  0.951,\n",
       "  1.0],\n",
       " [0.018,\n",
       "  0.029000000000000005,\n",
       "  0.05600000000000001,\n",
       "  0.10100000000000002,\n",
       "  0.129,\n",
       "  0.17299999999999996,\n",
       "  0.23200000000000004,\n",
       "  0.4640000000000001,\n",
       "  0.659,\n",
       "  0.905,\n",
       "  0.996])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_path1 = 'adv samples/MNIST/CW/00.15eps.npz'\n",
    "\n",
    "return_auc(adv_path1, normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74933c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
