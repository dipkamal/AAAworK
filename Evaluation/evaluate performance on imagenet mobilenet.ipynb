{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1154ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9015c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6288cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6e8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = '/home/db1702/Downloads/imagenet-mini/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ef0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "test = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "test_loader = DataLoader(test, shuffle=True, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854473a4",
   "metadata": {},
   "source": [
    "# For given adversarial images and benign images, collect metrics of feature attribution sensitivity and model prediction sensitivity. Save in csv that will be used for inspecting detection performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4cc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d271c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(x_batch, y_batch, spread):\n",
    "    new_x_batch = []\n",
    "    for x in x_batch:\n",
    "        x = x.data.cpu().numpy()\n",
    "        stdev = spread * (np.max(x)-np.min(x))\n",
    "        noise = np.random.normal(0, stdev, x.shape).astype(np.float32)\n",
    "        x_plus_noise = x + noise\n",
    "        x_plus_noise = np.clip(x_plus_noise, 0, 1)\n",
    "        x_plus_noise = torch.from_numpy(x_plus_noise).cpu()\n",
    "        new_x_batch.append(x_plus_noise)\n",
    "    new_batch = torch.stack(new_x_batch).to(device)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50304a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uniform noise function\n",
    "def add_uniform_noise(image):\n",
    "    # Generate uniform noise with mean 0 and standard deviation 25\n",
    "    noise = np.random.uniform(low=-0.5, high=0.5, size=image.shape).astype(np.float32)\n",
    "    noisy_image = np.clip(image + noise, 0, 1).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def uniform_noise(x_batch, y_batch): \n",
    "    # Convert batch of images to numpy array\n",
    "    images = x_batch.detach().cpu().numpy().transpose(0, 2, 3, 1) * 1.0\n",
    "    # Add Poisson noise to each image in the batch\n",
    "    noisy_images = [add_uniform_noise(image) for image in images]\n",
    "    # Convert noisy images back to Tensor format\n",
    "    noisy_inputs = torch.from_numpy(np.array(noisy_images).transpose(0, 3, 1, 2) / 1.0).float()\n",
    "    return noisy_inputs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a21aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_benign(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for benign\")\n",
    "    \n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['b_images']\n",
    "    adaptive_label = npobj['b_labels']\n",
    "    \n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.25)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.35)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "        attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "        logit_uniform\n",
    "    ], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\",\n",
    "        \"uniform attr\",\n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "        \"uniform logit\"\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Benign.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77980925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_adv(adv_path, normal_model): \n",
    "    \n",
    "    print(\"Computing metrics for {} for adv\")\n",
    "    npobj = np.load(adv_path)\n",
    "    adaptive_image = npobj['a_images']\n",
    "    adaptive_label = npobj['a_labels']\n",
    "    \n",
    "    #attribution robustness\n",
    "    attribution_gaussian1 = []\n",
    "    attribution_gaussian2 = []\n",
    "    attribution_gaussian3 = []\n",
    "    attribution_uniform = []\n",
    "    \n",
    "    #logit robustness\n",
    "    logit_gaussian1 = []\n",
    "    logit_gaussian2 = []\n",
    "    logit_gaussian3 = []\n",
    "    logit_uniform = []\n",
    "    \n",
    "    images, labels = torch.from_numpy(adaptive_image), torch.from_numpy(adaptive_label)\n",
    "    #images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    end = len(adaptive_label)\n",
    "    if end > 1000:\n",
    "        end = 1000\n",
    "    \n",
    "    for i in range(0, end, 2):\n",
    "        \n",
    "        images_adv, y_pred_adv = images[i:i+2], labels[i:i+2]\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        x_logits = normal_model(images_adv)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #approach: attribution and logit robustness\n",
    "        a_batch = quantus.explain(\n",
    "            model=normal_model, inputs=images_adv, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        gaussian_noisy_images_1 = make_noise(images_adv, y_pred_adv, spread = 0.15)\n",
    "        gaussian_logits_1 = normal_model(gaussian_noisy_images_1)\n",
    "        gaussian_noisy_images_2 = make_noise(images_adv, y_pred_adv, spread = 0.25)\n",
    "        gaussian_logits_2 = normal_model(gaussian_noisy_images_2)\n",
    "        gaussian_noisy_images_3 = make_noise(images_adv, y_pred_adv, spread = 0.35)\n",
    "        gaussian_logits_3 = normal_model(gaussian_noisy_images_3)\n",
    "        uniform_noisy_images = uniform_noise(images_adv, y_pred_adv)\n",
    "        uniform_logits = normal_model(uniform_noisy_images)\n",
    "        \n",
    "        \n",
    "        diff1 = torch.norm(x_logits-gaussian_logits_1,p=1, dim=1) \n",
    "        diff2 = torch.norm(x_logits-gaussian_logits_2,p=1, dim=1) \n",
    "        diff3 = torch.norm(x_logits-gaussian_logits_3,p=1, dim=1) \n",
    "        diff4 = torch.norm(x_logits-uniform_logits,p=1, dim=1) \n",
    "        \n",
    "        logit_gaussian1.extend(diff1.detach().cpu().numpy())\n",
    "        logit_gaussian2.extend(diff2.detach().cpu().numpy())\n",
    "        logit_gaussian3.extend(diff3.detach().cpu().numpy())\n",
    "        logit_uniform.extend(diff4.detach().cpu().numpy())\n",
    "        \n",
    "        a_batch_gaussian1 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_1, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian2 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_2, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_gaussian3 = quantus.explain(\n",
    "        model=normal_model, inputs=gaussian_noisy_images_3, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        a_batch_uniform = quantus.explain(\n",
    "        model=normal_model, inputs=uniform_noisy_images, targets=y_pred_adv, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian1):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian1.append(c)\n",
    "            \n",
    "        for a, b in zip(a_batch, a_batch_gaussian2):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian2.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_gaussian3):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_gaussian3.append(c)\n",
    "        \n",
    "        for a, b in zip(a_batch, a_batch_uniform):\n",
    "            c = np.linalg.norm(a.flatten()-b.flatten(),ord=1 )\n",
    "            attribution_uniform.append(c)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame([\n",
    "            \n",
    "            attribution_gaussian1,\n",
    "            attribution_gaussian2,\n",
    "            attribution_gaussian3,\n",
    "        attribution_uniform,\n",
    "            logit_gaussian1,\n",
    "            logit_gaussian2,\n",
    "            logit_gaussian3,\n",
    "    logit_uniform], index = [\n",
    "            \"Gaussian1 attribution\", \n",
    "            \"Gaussian2 attribution\", \n",
    "            \"Gaussian3 attribution\",\n",
    "        \"uniform attr\",\n",
    "            \"Gaussian1 logit robusntess\",\n",
    "            \"Gaussian2 logit robusntess\",\n",
    "            \"Gaussian3 logit robusntess\",\n",
    "        \"uniform logit\"\n",
    "                    ])\n",
    "            \n",
    "    path = \"adaptive_Adv.csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4c3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv1, a, b, adv2, c, d): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value1, value2 in zip(adv1, adv2): \n",
    "        if value1<a or value1>b:\n",
    "            TP += 1\n",
    "        else:\n",
    "            if value2<c or value2>d:\n",
    "                TP+=1\n",
    "            else: \n",
    "                FN+=1\n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed11de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ap2a, k, l, ap2b, m, n): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0 \n",
    "    TP=0\n",
    "    \n",
    "    for value6, value7 in zip(ap2a,ap2b):\n",
    "        if value6<k or value6>l:\n",
    "            FP +=1\n",
    "        else:\n",
    "            if value7<m or value7>n:\n",
    "                FP +=1\n",
    "\n",
    "    return (FP/(len(ap2a)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc203be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9f79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mobilet model first\n",
    "\n",
    "def load_imagenet_model():\n",
    "    model=torchvision.models.mobilenet_v3_small(weights=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb81e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4fac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_auc(adv_path, model):\n",
    "    #logitgaussian3\n",
    "    k=[1500, 1700,2000, 2510,2810,3000, 3200,3500, 6000]\n",
    "    l=[6700, 6700,6700, 6700,6700,6700,6700,6700, 6700]\n",
    "    \n",
    "    #attrgaussian3\n",
    "    m=[1000, 1400, 1580, 1750,1900, 2300, 3200, 3500, 6000]\n",
    "    n=[6600, 6600,6600, 6600,6600,6600,6600,6600,6600]\n",
    "\n",
    "    compute_metrics_benign(adv_path, model)\n",
    "    compute_metrics_adv(adv_path, model)\n",
    "    df_cifar = pd.read_csv(\"adaptive_Benign.csv\")\n",
    "    attr_gaussian3 = df_cifar.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3 = df_cifar.iloc[6].values.flatten().tolist()[1:]\n",
    "        \n",
    "    fpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        FPR = compute_FPR(logit_gaussian3, t1,t2, attr_gaussian3,t3,t4)\n",
    "        fpr_results.append(FPR/100)\n",
    "        \n",
    "    df_pgd_eps1 = pd.read_csv(\"adaptive_Adv.csv\")\n",
    "    attr_gaussian3_eps1 = df_pgd_eps1.iloc[2].values.flatten().tolist()[1:]\n",
    "    logit_gaussian3_eps1 = df_pgd_eps1.iloc[6].values.flatten().tolist()[1:]\n",
    "    \n",
    "    tpr_results =[]\n",
    "    for t1,t2,t3,t4 in zip(k,l,m,n):\n",
    "        TPR = compute_TPR(logit_gaussian3_eps1, t1,t2, attr_gaussian3_eps1,t3,t4)\n",
    "        tpr_results.append(TPR/100)\n",
    "    return sklearn.metrics.auc(fpr_results, tpr_results), fpr_results, tpr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901cb3d",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "997fa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adv_path1 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/FGSM/0.03137254901960784eps.npz'\n",
    "adv_path2 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/FGSM/0.06274509803921569eps.npz'\n",
    "adv_path3 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/FGSM/0.12549019607843137eps.npz'\n",
    "adv_path4 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/FGSM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27c92494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8204594999999999,\n",
       " [0.025,\n",
       "  0.052000000000000005,\n",
       "  0.11200000000000002,\n",
       "  0.198,\n",
       "  0.294,\n",
       "  0.544,\n",
       "  0.884,\n",
       "  0.936,\n",
       "  1.0],\n",
       " [0.115, 0.274, 0.505, 0.706, 0.823, 0.9419999999999998, 0.998, 1.0, 1.0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "810b5284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9136475, [0.026000000000000002, 0.061, 0.124, 0.201, 0.314, 0.559, 0.8960000000000001, 0.9469999999999998, 1.0], [0.279, 0.57, 0.813, 0.924, 0.971, 0.996, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.959767, [0.031, 0.061, 0.118, 0.204, 0.322, 0.559, 0.882, 0.93, 1.0], [0.7509999999999999, 0.919, 0.982, 0.995, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.98014, [0.019, 0.059, 0.115, 0.18, 0.277, 0.52, 0.865, 0.915, 1.0], [0.9689999999999999, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab8271",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c177cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/PGD/0.03137254901960784eps.npz'\n",
    "adv_path2 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/PGD/0.06274509803921569eps.npz'\n",
    "adv_path3 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/PGD/0.12549019607843137eps.npz'\n",
    "adv_path4 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/PGD/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f1044d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9552784999999999,\n",
       " [0.039, 0.077, 0.14, 0.225, 0.325, 0.569, 0.872, 0.924, 1.0],\n",
       " [0.986,\n",
       "  0.987,\n",
       "  0.9890000000000001,\n",
       "  0.99,\n",
       "  0.9940000000000001,\n",
       "  0.995,\n",
       "  0.997,\n",
       "  0.998,\n",
       "  1.0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89aa5eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9607490000000001, [0.039, 0.075, 0.144, 0.241, 0.3390000000000001, 0.539, 0.8809999999999999, 0.931, 1.0], [0.9990000000000001, 0.9990000000000001, 0.9990000000000001, 0.9990000000000001, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.967, [0.033, 0.065, 0.121, 0.221, 0.338, 0.551, 0.8859999999999999, 0.941, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.9670000000000002, [0.032, 0.065, 0.132, 0.23, 0.333, 0.569, 0.875, 0.935, 0.9990000000000001], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6365f",
   "metadata": {},
   "source": [
    "# CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beb865bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8666335000000001,\n",
       " [0.033, 0.07, 0.132, 0.229, 0.32899999999999996, 0.548, 0.878, 0.932, 1.0],\n",
       " [0.527, 0.569, 0.66, 0.856, 0.921, 0.956, 0.98, 0.991, 1.0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_path1 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/CW/0.15eps.npz'\n",
    "\n",
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc032a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_path1 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/BIM/0.03137254901960784eps.npz'\n",
    "adv_path2 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/BIM/0.06274509803921569eps.npz'\n",
    "adv_path3 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/BIM/0.12549019607843137eps.npz'\n",
    "adv_path4 = '/home/db1702/Desktop/data/virtual environments/adv detection by robustness/adv_detection/AAAI /adv samples/IMAGENET/MobileNet/BIM/0.25098039215686274eps.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5685dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48302700000000004,\n",
       " [0.018, 0.049, 0.107, 0.215, 0.317, 0.532, 0.8759999999999999, 0.936, 1.0],\n",
       " [0.261,\n",
       "  0.271,\n",
       "  0.284,\n",
       "  0.322,\n",
       "  0.36700000000000005,\n",
       "  0.439,\n",
       "  0.727,\n",
       "  0.804,\n",
       "  0.9990000000000001])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc, tpr, fpr = return_auc(adv_path1, normal_model)\n",
    "auc, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cf31dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.6353774999999999, [0.019, 0.067, 0.128, 0.22, 0.331, 0.535, 0.884, 0.936, 1.0], [0.515, 0.521, 0.526, 0.545, 0.564, 0.619, 0.79, 0.84, 0.9990000000000001])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.7671565, [0.026000000000000002, 0.074, 0.135, 0.212, 0.312, 0.527, 0.873, 0.93, 1.0], [0.727, 0.727, 0.728, 0.731, 0.737, 0.758, 0.8640000000000001, 0.904, 0.9990000000000001])\n",
      "----\n",
      "Computing metrics for {} for benign\n",
      "Computing metrics for {} for adv\n",
      "(0.8449150000000001, [0.012, 0.054000000000000006, 0.10400000000000001, 0.213, 0.32, 0.552, 0.871, 0.932, 1.0], [0.805, 0.806, 0.806, 0.813, 0.82, 0.84, 0.914, 0.946, 0.9990000000000001])\n"
     ]
    }
   ],
   "source": [
    "print(return_auc(adv_path2, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path3, normal_model))\n",
    "print('----')\n",
    "print(return_auc(adv_path4, normal_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2e649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
