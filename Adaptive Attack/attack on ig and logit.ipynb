{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07763d1",
   "metadata": {},
   "source": [
    "This notebook reproduces combined adaptive attack on both integrated gradient and logit where the goal of an adversary is to reduce the difference between the logits and feature attribution of benign and adversarial images in addition to change in label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "#from torchvision.models import resnet50 \n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torchvision.datasets import CIFAR10 \n",
    "from torch.utils.data import DataLoader \n",
    "from captum.attr import IntegratedGradients\n",
    "import torch.nn.functional as F\n",
    "#plot new and old images \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from captum.attr import *\n",
    "import quantus\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image as np arrays \n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074705cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_srelu import resnet50 as resnet50\n",
    "\n",
    "def load_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model\n",
    "\n",
    "modelpath = \"/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/Models/CIFAR10/resnet50/cifar.ckpt\"\n",
    "model = load_model(modelpath)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_attack_with_pgd_match(model, images, labels, eps=16/255, alpha=8/255, iters=40):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach()\n",
    "    \n",
    "    clean_logits = model(images)\n",
    "    \n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    feature_attr_orig = integrated_gradients.attribute(images, target=labels)\n",
    "    \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images \n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "    \n",
    "    adv_images = adv_images.detach().clone()\n",
    "    \n",
    "    steps = [301, 200, 100, 50]\n",
    "    cs = [5, 10, 20,30,50]\n",
    "    #cs = [0.001, 0.004, 0.01, 0.05]\n",
    "    for c, num_step in zip(cs, steps): \n",
    "        for i in range(num_step):\n",
    "            adv_images.requires_grad = True\n",
    "            outputs = model(adv_images)\n",
    "            _, target2 = torch.max(outputs.data, 1)\n",
    "\n",
    "            #calculate loss \n",
    "            cost_pgd = loss(outputs, labels)\n",
    "            feature_attr_perturbed = integrated_gradients.attribute(adv_images, target=target2) \n",
    "            l2_distance = torch.norm(feature_attr_perturbed - feature_attr_orig, p=2)\n",
    "            \n",
    "            #calculate logit loss\n",
    "            adv_logits = model(adv_images)\n",
    "            logit_loss = F.mse_loss(clean_logits, adv_logits)\n",
    "\n",
    "            #total cost\n",
    "            cost_total = cost_pgd + c*l2_distance + 10*logit_loss\n",
    "\n",
    "            #update adversarial images \n",
    "            grad = torch.autograd.grad(cost_total, adv_images, retain_graph=True)[0]\n",
    "            adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "            delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "            \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, eps=16/255, alpha=8/255, iters=40):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach() \n",
    "        \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images \n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "        \n",
    "       \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6c127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adversarial_images = []\n",
    "adversarial_labels = []\n",
    "benign_images = [] \n",
    "benign_labels = []\n",
    "pgd_images = []\n",
    "pgd_labels= []\n",
    "\n",
    "for step, (images, labels) in enumerate(test_loader):\n",
    "    perturbed_images = adaptive_attack_with_pgd_match(model, images, labels)\n",
    "    new_label = model(perturbed_images)\n",
    "    _, new = torch.max(new_label.data, 1)\n",
    "    adversarial_images.append(perturbed_images.detach().cpu().numpy())\n",
    "    adversarial_labels.append(new.detach().cpu().numpy())\n",
    "    \n",
    "    # Append benign images and labels to the batch\n",
    "    b_image, b_label = images.numpy(), labels.numpy()\n",
    "    benign_images.append(b_image)\n",
    "    benign_labels.append(b_label)\n",
    "    \n",
    "    #compute pgd image of the same batch too \n",
    "    pgdimages = pgd_attack(model, images, labels)\n",
    "    new_label = model(pgdimages)\n",
    "    _, pgdlabel = torch.max(new_label.data, 1)\n",
    "    pgd_images.append(pgdimages.detach().cpu().numpy())\n",
    "    pgd_labels.append(pgdlabel.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    if len(adversarial_images)%10==0:\n",
    "        print(len(adversarial_images))\n",
    "    \n",
    "    if len(adversarial_images) > 250:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "import os \n",
    "img = np.concatenate(adversarial_images)\n",
    "label = np.concatenate(adversarial_labels)\n",
    "b_img = np.concatenate(benign_images)\n",
    "b_lbl = np.concatenate(benign_labels)\n",
    "pgd_img = np.concatenate(pgd_images)\n",
    "pgd_lbl = np.concatenate(pgd_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/adaptive_attack_images_cifar/srelu' \n",
    "np.savez(os.path.join(save_dir, 'attack both ig and model/16255.npz'), adaptive_images=img, adaptive_labels=label, benign_images=b_img, benign_labels=b_lbl, pgd_images=pgd_img, pgd_labels=pgd_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/adaptive_attack_images_cifar/adaptive2.npz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "npobj = np.load(data_path)\n",
    "adaptive_image = npobj['adaptive_images']\n",
    "adaptive_label = npobj['adaptive_labels']\n",
    "ben_image = npobj['benign_images']\n",
    "ben_label = npobj['benign_labels']\n",
    "pgd_image = npobj['pgd_images']\n",
    "pgd_label =npobj['pgd_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_label, pgd_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names for CIFAR\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Access the image and label at the current index\n",
    "    image = np.transpose(ben_image[i], (1, 2, 0))  # Transpose to (height, width, channels)\n",
    "    label = ben_label[i]\n",
    "\n",
    "    # Plot the image\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names for CIFAR\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Access the image and label at the current index\n",
    "    image = np.transpose(adaptive_image[i], (1, 2, 0))  # Transpose to (height, width, channels)\n",
    "    label = adaptive_label[i]\n",
    "\n",
    "    # Plot the image\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names for CIFAR\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Access the image and label at the current index\n",
    "    image = np.transpose(pgd_image[i], (1, 2, 0))  # Transpose to (height, width, channels)\n",
    "    label = pgd_label[i]\n",
    "\n",
    "    # Plot the image\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get heatmaps \n",
    "\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "intgrad1 = quantus.normalise_func.normalise_by_negative(IntegratedGradients(model).attribute(inputs=images, target=labels, baselines=torch.zeros_like(images)).sum(axis=1).cpu().numpy())\n",
    "intgrad2 = quantus.normalise_func.normalise_by_negative(IntegratedGradients(model).attribute(inputs=perturbed_images, target=new, baselines=torch.zeros_like(perturbed_images)).sum(axis=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd322a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform simple pgd attack \n",
    "\n",
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, iters=40):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach() \n",
    "        \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images \n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "        \n",
    "       \n",
    "    return adv_images\n",
    "\n",
    "#compute pgd attack \n",
    "for images, labels in test_loader:\n",
    "    pgd_images = pgd_attack(model, images, labels)\n",
    "    print('Original label:', labels)\n",
    "    new_label = model(pgd_images)\n",
    "    _, pgdlabel = torch.max(new_label.data, 1)\n",
    "    print('pgdlabel:', pgdlabel)\n",
    "    break  # Break after processing one batch\n",
    "\n",
    "#compute pgd attributions \n",
    "intgrad3 = quantus.normalise_func.normalise_by_negative(IntegratedGradients(model).attribute(inputs=pgd_images, target=pgdlabel, baselines=torch.zeros_like(pgd_images)).sum(axis=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f270f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when i put some higher constants on c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_images = x_batch.shape[0]\n",
    "nr_images = 5\n",
    "fig, axes = plt.subplots(nrows=nr_images, ncols=6, figsize=(nr_images*2.5, int(nr_images*3)))\n",
    "for i,j in zip(range(nr_images),range(0,5)):\n",
    "    \n",
    "    \n",
    "    axes[i, 0].imshow((np.moveaxis((images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 0].title.set_text(f\"normal\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    \n",
    "    axes[i, 1].imshow(np.moveaxis(intgrad1[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 1].title.set_text(f\"\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "    \n",
    "    axes[i, 2].imshow((np.moveaxis((pgd_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 2].title.set_text(f\"pgd\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "    \n",
    "    axes[i, 3].imshow(np.moveaxis(intgrad3[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 3].title.set_text(f\"\")\n",
    "    axes[i, 3].axis(\"off\")\n",
    "\n",
    "    axes[i, 4].imshow((np.moveaxis((perturbed_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 4].title.set_text(f\"adv\")\n",
    "    axes[i, 4].axis(\"off\")\n",
    "    \n",
    "    axes[i, 5].imshow(np.moveaxis(intgrad2[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 5].title.set_text(f\"\")\n",
    "    axes[i, 5].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when i had no c in loss function with smaller c value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_images = x_batch.shape[0]\n",
    "nr_images = 5\n",
    "fig, axes = plt.subplots(nrows=nr_images, ncols=6, figsize=(nr_images*2.5, int(nr_images*3)))\n",
    "for i,j in zip(range(nr_images),range(0,5)):\n",
    "    \n",
    "    \n",
    "    axes[i, 0].imshow((np.moveaxis((images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 0].title.set_text(f\"normal\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    \n",
    "    axes[i, 1].imshow(np.moveaxis(intgrad1[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 1].title.set_text(f\"\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "    \n",
    "    axes[i, 2].imshow((np.moveaxis((pgd_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 2].title.set_text(f\"pgd\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "    \n",
    "    axes[i, 3].imshow(np.moveaxis(intgrad3[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 3].title.set_text(f\"\")\n",
    "    axes[i, 3].axis(\"off\")\n",
    "\n",
    "    axes[i, 4].imshow((np.moveaxis((perturbed_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 4].title.set_text(f\"adv\")\n",
    "    axes[i, 4].axis(\"off\")\n",
    "    \n",
    "    axes[i, 5].imshow(np.moveaxis(intgrad2[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 5].title.set_text(f\"\")\n",
    "    axes[i, 5].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070481d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when i had c in loss function with smaller c value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe99028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_images = x_batch.shape[0]\n",
    "nr_images = 5\n",
    "fig, axes = plt.subplots(nrows=nr_images, ncols=6, figsize=(nr_images*2.5, int(nr_images*3)))\n",
    "for i,j in zip(range(nr_images),range(0,5)):\n",
    "    \n",
    "    \n",
    "    axes[i, 0].imshow((np.moveaxis((images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 0].title.set_text(f\"normal\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    \n",
    "    axes[i, 1].imshow(np.moveaxis(intgrad1[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 1].title.set_text(f\"\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "    \n",
    "    axes[i, 2].imshow((np.moveaxis((pgd_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 2].title.set_text(f\"pgd\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "    \n",
    "    axes[i, 3].imshow(np.moveaxis(intgrad3[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 3].title.set_text(f\"\")\n",
    "    axes[i, 3].axis(\"off\")\n",
    "\n",
    "    axes[i, 4].imshow((np.moveaxis((perturbed_images[j].cpu().numpy()), 0, -1)*255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 4].title.set_text(f\"adv\")\n",
    "    axes[i, 4].axis(\"off\")\n",
    "    \n",
    "    axes[i, 5].imshow(np.moveaxis(intgrad2[j], 0,-1), cmap=\"seismic\")\n",
    "    axes[i, 5].title.set_text(f\"\")\n",
    "    axes[i, 5].axis(\"off\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de28553",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1= sum(adaptive_time)/(10*3)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055db49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check time \n",
    "adaptive_time = [] \n",
    "\n",
    "\n",
    "for step, (images, labels) in enumerate(test_loader):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    perturbed_images = adaptive_attack_with_pgd_match(model, images, labels)\n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time \n",
    "    adaptive_time.append(exec_time)\n",
    "        \n",
    "    if step > 5:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cae6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4c779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
