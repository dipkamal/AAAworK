{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6d8b12",
   "metadata": {},
   "source": [
    "This notebook provides adaptive attack on integrated gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torchvision.datasets import CIFAR10 \n",
    "from torch.utils.data import DataLoader \n",
    "from captum.attr import IntegratedGradients\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from captum.attr import *\n",
    "import quantus\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image as np arrays \n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074705cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_srelu import resnet50 as resnet50\n",
    "\n",
    "def load_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model\n",
    "\n",
    "modelpath = \"/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/Models/CIFAR10/resnet50/cifar.ckpt\"\n",
    "model = load_model(modelpath)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_attack(model, images, labels, eps=16/255, alpha=8/255, iters=40):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach() \n",
    "    \n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    feature_attr_orig = integrated_gradients.attribute(images, target=labels)\n",
    "    \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images \n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "    \n",
    "    adv_images = adv_images.detach().clone()\n",
    "    \n",
    "    steps = [301, 200, 100, 50]\n",
    "    cs = [5, 10, 20,30,50]\n",
    "    #cs = [0.001, 0.004, 0.01, 0.05]\n",
    "    for c, num_step in zip(cs, steps): \n",
    "        for i in range(num_step):\n",
    "            adv_images.requires_grad = True\n",
    "            outputs = model(adv_images)\n",
    "            _, target2 = torch.max(outputs.data, 1)\n",
    "\n",
    "            #calculate loss \n",
    "            cost_pgd = loss(outputs, labels)\n",
    "            feature_attr_perturbed = integrated_gradients.attribute(adv_images, target=target2) \n",
    "            l2_distance = torch.norm(feature_attr_perturbed - feature_attr_orig, p=2)\n",
    "\n",
    "            #total cost\n",
    "            cost_total = cost_pgd + c*l2_distance\n",
    "\n",
    "            #update adversarial images \n",
    "            grad = torch.autograd.grad(cost_total, adv_images, retain_graph=True)[0]\n",
    "            adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "            delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "            \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, eps=16/255, alpha=8/255, iters=40):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach() \n",
    "        \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images \n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "        \n",
    "       \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6c127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adversarial_images = []\n",
    "adversarial_labels = []\n",
    "benign_images = [] \n",
    "benign_labels = []\n",
    "pgd_images = []\n",
    "pgd_labels= []\n",
    "\n",
    "for step, (images, labels) in enumerate(test_loader):\n",
    "    perturbed_images = adaptive_attack(model, images, labels)\n",
    "    new_label = model(perturbed_images)\n",
    "    _, new = torch.max(new_label.data, 1)\n",
    "    adversarial_images.append(perturbed_images.detach().cpu().numpy())\n",
    "    adversarial_labels.append(new.detach().cpu().numpy())\n",
    "    \n",
    "    # Append benign images and labels to the batch\n",
    "    b_image, b_label = images.numpy(), labels.numpy()\n",
    "    benign_images.append(b_image)\n",
    "    benign_labels.append(b_label)\n",
    "    \n",
    "    #compute pgd image of the same batch too \n",
    "    pgdimages = pgd_attack(model, images, labels)\n",
    "    new_label = model(pgdimages)\n",
    "    _, pgdlabel = torch.max(new_label.data, 1)\n",
    "    pgd_images.append(pgdimages.detach().cpu().numpy())\n",
    "    pgd_labels.append(pgdlabel.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    if len(adversarial_images)%10==0:\n",
    "        print(len(adversarial_images))\n",
    "    \n",
    "    if len(adversarial_images) > 250:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "import os \n",
    "img = np.concatenate(adversarial_images)\n",
    "label = np.concatenate(adversarial_labels)\n",
    "b_img = np.concatenate(benign_images)\n",
    "b_lbl = np.concatenate(benign_labels)\n",
    "pgd_img = np.concatenate(pgd_images)\n",
    "pgd_lbl = np.concatenate(pgd_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/adaptive_attack_images_cifar/srelu' \n",
    "np.savez(os.path.join(save_dir, '16255IGAttackImages.npz'), adaptive_images=img, adaptive_labels=label, benign_images=b_img, benign_labels=b_lbl, pgd_images=pgd_img, pgd_labels=pgd_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time \n",
    "import time \n",
    "\n",
    "adv_time = []\n",
    "\n",
    "for step, (images, labels) in enumerate(test_loader):\n",
    "    start_time = time.time()\n",
    "    perturbed_images = adaptive_attack(model, images, labels)\n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time \n",
    "    adv_time.append(exec_time)\n",
    "    \n",
    "    if step > 3:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(adv_time)/(5*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f6a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
