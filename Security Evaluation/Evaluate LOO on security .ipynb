{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd4eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926980c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3f0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34be232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' A basic neural network model '''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()         #python2 : super(MLP, self).__init__()\n",
    "        #defining the network's operations\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], output_size)\n",
    "\n",
    "    def forward(self, x, softmax=False): \n",
    "        a = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x.float())))))\n",
    "        if softmax:\n",
    "            y_pred = F.softmax(a, dim=1)\n",
    "        else:\n",
    "            y_pred = a\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20a940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=121, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size=121\n",
    "hidden_size=[256,256]\n",
    "output_size=2\n",
    "model = Network(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(\"./model.pytorch\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ac13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in adv: \n",
    "        if value>th:\n",
    "            TP += 1\n",
    "        else: \n",
    "            FN += 1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3137b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ben, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<th:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(FP+TN))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fee93b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        #print(score_75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        #print(score_25)\n",
    "        score_qt = score_75 - score_25\n",
    "       # print(score_qt)\n",
    "        scores.append(score_qt)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "424ae876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fs(model, x_batch, y_batch, train_fpr):\n",
    "    distances = get_attr(model, x_batch, y_batch)\n",
    "    selected_distance_idx = int(np.ceil(len(x_batch) * (1-train_fpr)))\n",
    "    threshold = sorted(distances)[selected_distance_idx-1]\n",
    "    threshold = threshold\n",
    "    return threshold\n",
    "\n",
    "def get_attr(model, x_batch, y_batch):\n",
    "    a_batch_intgrad = quantus.explain(\n",
    "            model=model, inputs=x_batch, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "    iqr = compute_iqr(a_batch_intgrad)\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e635eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on benign samples and save metrics\n",
    "def compute_benign_metrics(test_loader, model):\n",
    "    fs = []\n",
    "    for image, label in test_loader: \n",
    "        image, label = image.to(device), label.to(device)\n",
    "        d = get_attr(model, image, label)    \n",
    "        fs.extend(d)\n",
    "    return fs\n",
    "\n",
    "\n",
    "#evaluate on adv samples and save metrics\n",
    "def compute_adv_metrics(test_loader, model):\n",
    "    fs = []\n",
    "    for image, label in test_loader: \n",
    "        image, label = image.to(device), label.to(device)\n",
    "        d = get_attr(model, image, label)    \n",
    "        fs.extend(d)\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9996f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data.drop(self.data.columns[0], axis=1)  # Remove unnecessary index column\n",
    "        self.features = self.data.iloc[:, :-1].values  # Features (all columns except the last)\n",
    "        self.labels = self.data.iloc[:, -1].values     # Labels (last column)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Load CSV file and split into train and test sets\n",
    "dataset = CustomDataset('clean_examples.csv')\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "053dca86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for 0.01 FPR is 19.744899074236553.\n",
      "Threshold for 0.05 FPR is 16.84036260025174.\n",
      "Threshold for 0.1 FPR is 15.667794797934738.\n"
     ]
    }
   ],
   "source": [
    "FPR = [0.01,0.05,0.1]\n",
    "final_th = []\n",
    "for fpr in FPR:\n",
    "    t=[]\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        threshold = train_fs(model, x_batch, y_batch, fpr)\n",
    "        t.append(threshold.item())\n",
    "        if step==50:\n",
    "            break\n",
    "    th = sum(t)/len(t)\n",
    "    print(\"Threshold for {} FPR is {}.\".format(fpr, th))\n",
    "    final_th.append(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4a2a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.5,1,3,7,9,10,11,12,13,14,15,16,17,19,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5bb00499",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "41a050ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22bfe5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM3.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6471f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM4.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7bf56814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.9996104402025711,\n",
       " 0.8955979742890534,\n",
       " 0.777561355668095,\n",
       " 0.7234125438254773,\n",
       " 0.6606934164394235,\n",
       " 0.5652512660693416,\n",
       " 0.4737047136735489,\n",
       " 0.26373198285936894,\n",
       " 0.14218932606155044,\n",
       " 0.08804051421893261,\n",
       " 0.06973120373977405,\n",
       " 0.014803272302298403,\n",
       " 0.0038955979742890533]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe630059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44779995459435473, 0.055272568883801346)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d185fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3a9a89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78a3f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD3.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a34b6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD4.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa53f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5655518204825898, 0.06317246132627682)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e73b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6f317b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cbdbb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM3.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f10b5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM4.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "53bca9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4748719134366868, 0.013358656362423123)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a2be2",
   "metadata": {},
   "source": [
    "# CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bed76539",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW21.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89e60961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW22.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7f89978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW23.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ce6e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW24.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa2945af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7726578267298118, 0.0014484560779117676)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be424c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
