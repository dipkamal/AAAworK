{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34890cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40edb3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5f4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61a9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' A basic neural network model '''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()         #python2 : super(MLP, self).__init__()\n",
    "        #defining the network's operations\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], output_size)\n",
    "\n",
    "    def forward(self, x, softmax=False): \n",
    "        x = x.reshape(-1,47)\n",
    "        a = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x.float())))))\n",
    "        if softmax:\n",
    "            y_pred = F.softmax(a, dim=1)\n",
    "        else:\n",
    "            y_pred = a\n",
    "        #print(y_pred.shape)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd160c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on : cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on : {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5764fff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=47, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 47\n",
    "hidden_size=[64,64]\n",
    "output_size=2\n",
    "model = Network(input_size, hidden_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1242d537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=47, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c211a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>3.333333e+02</td>\n",
       "      <td>1.753777e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>54.666668</td>\n",
       "      <td>133.90544</td>\n",
       "      <td>2898.7500</td>\n",
       "      <td>4095.5662</td>\n",
       "      <td>119.999920</td>\n",
       "      <td>0.100646</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>3.310000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>11595.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115.666664</td>\n",
       "      <td>173.50000</td>\n",
       "      <td>1656.4286</td>\n",
       "      <td>1547.7377</td>\n",
       "      <td>125.453190</td>\n",
       "      <td>0.158852</td>\n",
       "      <td>6.714855e+06</td>\n",
       "      <td>2.580000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>11595.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.818477</td>\n",
       "      <td>1.469746</td>\n",
       "      <td>8.504870e+05</td>\n",
       "      <td>1.697628e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>173.20508</td>\n",
       "      <td>1932.5000</td>\n",
       "      <td>1977.8129</td>\n",
       "      <td>83350.850000</td>\n",
       "      <td>63.064957</td>\n",
       "      <td>1.783875e+04</td>\n",
       "      <td>4.638334e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>11595.0</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Destination Port   Fwd Packet Length Mean   \n",
       "0           0               80.0                 0.000000  \\\n",
       "1           1               80.0                54.666668   \n",
       "2           2               80.0               115.666664   \n",
       "3           3               80.0                 6.000000   \n",
       "4           4               80.0               100.000000   \n",
       "\n",
       "    Fwd Packet Length Std   Bwd Packet Length Mean   Bwd Packet Length Std   \n",
       "0                 0.00000                   0.0000                  0.0000  \\\n",
       "1               133.90544                2898.7500               4095.5662   \n",
       "2               173.50000                1656.4286               1547.7377   \n",
       "3                 0.00000                   0.0000                  0.0000   \n",
       "4               173.20508                1932.5000               1977.8129   \n",
       "\n",
       "   Flow Bytes/s   Flow Packets/s   Flow IAT Mean   Flow IAT Std  ...   \n",
       "0      0.000000      4000.000000    3.333333e+02   1.753777e+02  ...  \\\n",
       "1    119.999920         0.100646    1.100000e+07   3.310000e+07  ...   \n",
       "2    125.453190         0.158852    6.714855e+06   2.580000e+07  ...   \n",
       "3      8.818477         1.469746    8.504870e+05   1.697628e+06  ...   \n",
       "4  83350.850000        63.064957    1.783875e+04   4.638334e+04  ...   \n",
       "\n",
       "    Subflow Bwd Bytes  Init_Win_bytes_forward   Init_Win_bytes_backward   \n",
       "0                 0.0                   251.0                      -1.0  \\\n",
       "1             11595.0                   251.0                     235.0   \n",
       "2             11595.0                   274.0                     235.0   \n",
       "3                 0.0                   256.0                      -1.0   \n",
       "4             11595.0                 29200.0                     235.0   \n",
       "\n",
       "    act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std   \n",
       "0                0.0                   32.0          0.0          0.0  \\\n",
       "1                1.0                   32.0          4.0          0.0   \n",
       "2                3.0                   32.0       1003.0          0.0   \n",
       "3                4.0                   20.0          0.0          0.0   \n",
       "4                1.0                   32.0          0.0          0.0   \n",
       "\n",
       "    Active Max   Active Min  Class  \n",
       "0          0.0          0.0    1.0  \n",
       "1          4.0          4.0    1.0  \n",
       "2       1003.0       1003.0    1.0  \n",
       "3          0.0          0.0    1.0  \n",
       "4          0.0          0.0    1.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_examples.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58ea108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR(adv, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in adv: \n",
    "        if value>th:\n",
    "            TP += 1\n",
    "        else: \n",
    "            FN += 1\n",
    "    \n",
    "    \n",
    "    return (TP/(TP+FN))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30625448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FPR(ben, th): \n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP = 0 \n",
    "    TP=0\n",
    "    \n",
    "    for value in ben: \n",
    "        if value<th:\n",
    "            TN += 1\n",
    "        else: \n",
    "            FP += 1\n",
    "    \n",
    "    \n",
    "    return (FP/(FP+TN))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbc3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(attr):\n",
    "    scores = []\n",
    "    for i in range(len(attr)):\n",
    "        a = attr[i].flatten()\n",
    "        score_75 = np.percentile(a, 75)\n",
    "        #print(score_75)\n",
    "        score_25 = np.percentile(a, 25)\n",
    "        #print(score_25)\n",
    "        score_qt = score_75 - score_25\n",
    "       # print(score_qt)\n",
    "        scores.append(score_qt)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec176f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fs(model, x_batch, y_batch, train_fpr):\n",
    "    distances = get_attr(model, x_batch, y_batch)\n",
    "    selected_distance_idx = int(np.ceil(len(x_batch) * (1-train_fpr)))\n",
    "    threshold = sorted(distances)[selected_distance_idx-1]\n",
    "    threshold = threshold\n",
    "    return threshold\n",
    "\n",
    "def get_attr(model, x_batch, y_batch):\n",
    "    a_batch_intgrad = quantus.explain(\n",
    "            model=model, inputs=x_batch, targets=y_batch, **{\"method:\": \"IntegratedGradient\", \"device\": device})\n",
    "        \n",
    "    iqr = compute_iqr(a_batch_intgrad)\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "114bf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on benign samples and save metrics\n",
    "def compute_benign_metrics(test_loader, model):\n",
    "    fs = []\n",
    "    for image, label in test_loader: \n",
    "        image, label = image.to(device), label.to(device)\n",
    "        d = get_attr(model, image, label)    \n",
    "        fs.extend(d)\n",
    "    return fs\n",
    "\n",
    "\n",
    "#evaluate on adv samples and save metrics\n",
    "def compute_adv_metrics(test_loader, model):\n",
    "    fs = []\n",
    "    for image, label in test_loader: \n",
    "        image, label = image.to(device), label.to(device)\n",
    "        d = get_attr(model, image, label)    \n",
    "        fs.extend(d)\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e56d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data.drop(self.data.columns[0], axis=1)  # Remove unnecessary index column\n",
    "        self.features = self.data.iloc[:, :-1].values  # Features (all columns except the last)\n",
    "        self.labels = self.data.iloc[:, -1].values     # Labels (last column)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Load CSV file and split into train and test sets\n",
    "dataset = CustomDataset('clean_examples.csv')\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d15f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for 0.01 FPR is 0.02216381465504859.\n",
      "Threshold for 0.05 FPR is 0.0194647861872891.\n",
      "Threshold for 0.1 FPR is 0.018963445242786526.\n"
     ]
    }
   ],
   "source": [
    "FPR = [0.01,0.05,0.1]\n",
    "final_th = []\n",
    "for fpr in FPR:\n",
    "    t=[]\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        threshold = train_fs(model, x_batch, y_batch, fpr)\n",
    "        t.append(threshold.item())\n",
    "        if step==50:\n",
    "            break\n",
    "    th = sum(t)/len(t)\n",
    "    print(\"Threshold for {} FPR is {}.\".format(fpr, th))\n",
    "    final_th.append(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ded0d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.022,0.021,0.019,0.017,0.016,0.015,0.013,0.010,0.008,0.006,0.003,0.001,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d7385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.99, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42faaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_FGSM2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.99, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "806c535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5509811745841291, 0.060412886508727115)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ea04a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5ab381",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_PGD2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e078e3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5135758612338803, 0.055162408427680554)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d09d47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36e2aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_BIM2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f020fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4445235969001635, 0.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b69b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW1.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c7066b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_CW2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b078aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4297269479929769, 0.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sc), np.std(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcfc961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_autoPGD.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b9007a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dist_ben = compute_benign_metrics(test_loader, model)\n",
    "\n",
    "advdataset = CustomDataset('adversarial_examples_autoPGD2.csv')\n",
    "advtrain_data, advtest_data = train_test_split(advdataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 64\n",
    "train_loader_adv = DataLoader(advtrain_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_adv = DataLoader(advtest_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dist_adv = compute_adv_metrics(test_loader_adv, model)\n",
    "\n",
    "fpr_results = []\n",
    "for th in threshold:\n",
    "    FPR = compute_FPR(dist_ben, th)\n",
    "    fpr_results.append(FPR/100)\n",
    "tpr_results = []\n",
    "for th in threshold:\n",
    "    TPR = compute_TPR(dist_adv, th)\n",
    "    tpr_results.append(TPR/100)\n",
    "    \n",
    "score = sklearn.metrics.auc(fpr_results, tpr_results)\n",
    "sc.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d2a8ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5724471756372222, 0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score), np.std(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09be9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
