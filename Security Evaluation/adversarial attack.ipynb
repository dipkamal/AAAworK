{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753d7d74",
   "metadata": {},
   "source": [
    "The following code is based on the work: A Deeper Analysis of Adversarial Examples in Intrusion Detection by Mohamed Amine Merzouk, Frederic Cuppens,Nora Boulahia-Cuppens3, and Reda Yaich. Official github [repo](https://github.com/mamerzouk/adversarial_analysis/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2503ddbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import copy\n",
    "import time as time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent, DeepFool, CarliniL2Method, CarliniLInfMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ca07c",
   "metadata": {},
   "source": [
    "# NSL-KDD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c093e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading and extracting the dataset if it doesn't exist\n",
    "!if [ ! -d \"./NSL-KDD\" ]; then wget http://205.174.165.80/CICDataset/NSL-KDD/Dataset/NSL-KDD.zip; mkdir NSL-KDD; unzip NSL-KDD.zip -d NSL-KDD; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "495bebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the training and testing datasets from .CSV to Pandas DataFrames\n",
    "features = ['1 Duration', '2 Protocol-type : ', '3 Service : ', '4 Flag : ', '5 Src-bytes', '6 Dst-bytes', '7 Land', '8 Wrong-fragment', '9 Urgent', '10 Hot', '11 Num-failed-logins', '12 Logged-in', '13 Num-compromised', '14 Root-shell', '15 Su-attempted', '16 Num-root', '17 Num-file-creations', '18 Num-shells', '19 Num-access-files', '20 Num-outbound-cmds', '21 Is-host-login', '22 Is-guest-login', '23 Count', '24 Srv-count', '25 Serror-rate', '26 Srv-serror-rate', '27 Rerror-rate', '28 Srv-rerror-rate', '29 Same-srv-rate', '30 Diff-srv-rate', '31 Srv-diff-host-rate', '32 Dst-host-count', '33 Dst-host-srv-count', '34 Dst-host-same-srv-rate', '35 Dst-host-diff-srv-rate', '36 Dst-host-same-src-port-rate', '37 Dst-host-srv-diff-host-rate', '38 Dst-host-serror-rate', '39 Dst-host-srv-serror-rate', '40 Dst-host-rerror-rate', '41 Dst-host-srv-rerror-rate', '42 Attack_type', '43 Difficulty']\n",
    "df_training = pd.read_csv('./NSL-KDD/KDDTrain+.txt', names=features)\n",
    "df_testing = pd.read_csv('./NSL-KDD/KDDTest+.txt', names=features)\n",
    "# Stack the training and test sets\n",
    "data = pd.concat([df_training, df_testing], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c877391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Duration</th>\n",
       "      <th>2 Protocol-type :</th>\n",
       "      <th>3 Service :</th>\n",
       "      <th>4 Flag :</th>\n",
       "      <th>5 Src-bytes</th>\n",
       "      <th>6 Dst-bytes</th>\n",
       "      <th>7 Land</th>\n",
       "      <th>8 Wrong-fragment</th>\n",
       "      <th>9 Urgent</th>\n",
       "      <th>10 Hot</th>\n",
       "      <th>11 Num-failed-logins</th>\n",
       "      <th>12 Logged-in</th>\n",
       "      <th>13 Num-compromised</th>\n",
       "      <th>14 Root-shell</th>\n",
       "      <th>15 Su-attempted</th>\n",
       "      <th>16 Num-root</th>\n",
       "      <th>17 Num-file-creations</th>\n",
       "      <th>18 Num-shells</th>\n",
       "      <th>19 Num-access-files</th>\n",
       "      <th>20 Num-outbound-cmds</th>\n",
       "      <th>21 Is-host-login</th>\n",
       "      <th>22 Is-guest-login</th>\n",
       "      <th>23 Count</th>\n",
       "      <th>24 Srv-count</th>\n",
       "      <th>25 Serror-rate</th>\n",
       "      <th>26 Srv-serror-rate</th>\n",
       "      <th>27 Rerror-rate</th>\n",
       "      <th>28 Srv-rerror-rate</th>\n",
       "      <th>29 Same-srv-rate</th>\n",
       "      <th>30 Diff-srv-rate</th>\n",
       "      <th>31 Srv-diff-host-rate</th>\n",
       "      <th>32 Dst-host-count</th>\n",
       "      <th>33 Dst-host-srv-count</th>\n",
       "      <th>34 Dst-host-same-srv-rate</th>\n",
       "      <th>35 Dst-host-diff-srv-rate</th>\n",
       "      <th>36 Dst-host-same-src-port-rate</th>\n",
       "      <th>37 Dst-host-srv-diff-host-rate</th>\n",
       "      <th>38 Dst-host-serror-rate</th>\n",
       "      <th>39 Dst-host-srv-serror-rate</th>\n",
       "      <th>40 Dst-host-rerror-rate</th>\n",
       "      <th>41 Dst-host-srv-rerror-rate</th>\n",
       "      <th>42 Attack_type</th>\n",
       "      <th>43 Difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>SF</td>\n",
       "      <td>794</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>141</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22540</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>317</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>197</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>54540</td>\n",
       "      <td>8314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>back</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22542</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>255</td>\n",
       "      <td>252</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22543</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>sunrpc</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>255</td>\n",
       "      <td>21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>mscan</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148517 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1 Duration 2 Protocol-type :  3 Service :  4 Flag :   5 Src-bytes   \n",
       "0               0                tcp     ftp_data        SF          491  \\\n",
       "1               0                udp        other        SF          146   \n",
       "2               0                tcp      private        S0            0   \n",
       "3               0                tcp         http        SF          232   \n",
       "4               0                tcp         http        SF          199   \n",
       "...           ...                ...          ...       ...          ...   \n",
       "22539           0                tcp         smtp        SF          794   \n",
       "22540           0                tcp         http        SF          317   \n",
       "22541           0                tcp         http        SF        54540   \n",
       "22542           0                udp     domain_u        SF           42   \n",
       "22543           0                tcp       sunrpc       REJ            0   \n",
       "\n",
       "       6 Dst-bytes  7 Land  8 Wrong-fragment  9 Urgent  10 Hot   \n",
       "0                0       0                 0         0       0  \\\n",
       "1                0       0                 0         0       0   \n",
       "2                0       0                 0         0       0   \n",
       "3             8153       0                 0         0       0   \n",
       "4              420       0                 0         0       0   \n",
       "...            ...     ...               ...       ...     ...   \n",
       "22539          333       0                 0         0       0   \n",
       "22540          938       0                 0         0       0   \n",
       "22541         8314       0                 0         0       2   \n",
       "22542           42       0                 0         0       0   \n",
       "22543            0       0                 0         0       0   \n",
       "\n",
       "       11 Num-failed-logins  12 Logged-in  13 Num-compromised  14 Root-shell   \n",
       "0                         0             0                   0              0  \\\n",
       "1                         0             0                   0              0   \n",
       "2                         0             0                   0              0   \n",
       "3                         0             1                   0              0   \n",
       "4                         0             1                   0              0   \n",
       "...                     ...           ...                 ...            ...   \n",
       "22539                     0             1                   0              0   \n",
       "22540                     0             1                   0              0   \n",
       "22541                     0             1                   1              0   \n",
       "22542                     0             0                   0              0   \n",
       "22543                     0             0                   0              0   \n",
       "\n",
       "       15 Su-attempted  16 Num-root  17 Num-file-creations  18 Num-shells   \n",
       "0                    0            0                      0              0  \\\n",
       "1                    0            0                      0              0   \n",
       "2                    0            0                      0              0   \n",
       "3                    0            0                      0              0   \n",
       "4                    0            0                      0              0   \n",
       "...                ...          ...                    ...            ...   \n",
       "22539                0            0                      0              0   \n",
       "22540                0            0                      0              0   \n",
       "22541                0            0                      0              0   \n",
       "22542                0            0                      0              0   \n",
       "22543                0            0                      0              0   \n",
       "\n",
       "       19 Num-access-files  20 Num-outbound-cmds  21 Is-host-login   \n",
       "0                        0                     0                 0  \\\n",
       "1                        0                     0                 0   \n",
       "2                        0                     0                 0   \n",
       "3                        0                     0                 0   \n",
       "4                        0                     0                 0   \n",
       "...                    ...                   ...               ...   \n",
       "22539                    0                     0                 0   \n",
       "22540                    0                     0                 0   \n",
       "22541                    0                     0                 0   \n",
       "22542                    0                     0                 0   \n",
       "22543                    0                     0                 0   \n",
       "\n",
       "       22 Is-guest-login  23 Count  24 Srv-count  25 Serror-rate   \n",
       "0                      0         2             2             0.0  \\\n",
       "1                      0        13             1             0.0   \n",
       "2                      0       123             6             1.0   \n",
       "3                      0         5             5             0.2   \n",
       "4                      0        30            32             0.0   \n",
       "...                  ...       ...           ...             ...   \n",
       "22539                  0         1             1             0.0   \n",
       "22540                  0         2            11             0.0   \n",
       "22541                  0         5            10             0.0   \n",
       "22542                  0         4             6             0.0   \n",
       "22543                  0         4            10             0.0   \n",
       "\n",
       "       26 Srv-serror-rate  27 Rerror-rate  28 Srv-rerror-rate   \n",
       "0                     0.0             0.0                 0.0  \\\n",
       "1                     0.0             0.0                 0.0   \n",
       "2                     1.0             0.0                 0.0   \n",
       "3                     0.2             0.0                 0.0   \n",
       "4                     0.0             0.0                 0.0   \n",
       "...                   ...             ...                 ...   \n",
       "22539                 0.0             0.0                 0.0   \n",
       "22540                 0.0             0.0                 0.0   \n",
       "22541                 0.0             0.0                 0.0   \n",
       "22542                 0.0             0.0                 0.0   \n",
       "22543                 0.0             1.0                 1.0   \n",
       "\n",
       "       29 Same-srv-rate  30 Diff-srv-rate  31 Srv-diff-host-rate   \n",
       "0                  1.00              0.00                   0.00  \\\n",
       "1                  0.08              0.15                   0.00   \n",
       "2                  0.05              0.07                   0.00   \n",
       "3                  1.00              0.00                   0.00   \n",
       "4                  1.00              0.00                   0.09   \n",
       "...                 ...               ...                    ...   \n",
       "22539              1.00              0.00                   0.00   \n",
       "22540              1.00              0.00                   0.18   \n",
       "22541              1.00              0.00                   0.20   \n",
       "22542              1.00              0.00                   0.33   \n",
       "22543              0.25              1.00                   1.00   \n",
       "\n",
       "       32 Dst-host-count  33 Dst-host-srv-count  34 Dst-host-same-srv-rate   \n",
       "0                    150                     25                       0.17  \\\n",
       "1                    255                      1                       0.00   \n",
       "2                    255                     26                       0.10   \n",
       "3                     30                    255                       1.00   \n",
       "4                    255                    255                       1.00   \n",
       "...                  ...                    ...                        ...   \n",
       "22539                100                    141                       0.72   \n",
       "22540                197                    255                       1.00   \n",
       "22541                255                    255                       1.00   \n",
       "22542                255                    252                       0.99   \n",
       "22543                255                     21                       0.08   \n",
       "\n",
       "       35 Dst-host-diff-srv-rate  36 Dst-host-same-src-port-rate   \n",
       "0                           0.03                            0.17  \\\n",
       "1                           0.60                            0.88   \n",
       "2                           0.05                            0.00   \n",
       "3                           0.00                            0.03   \n",
       "4                           0.00                            0.00   \n",
       "...                          ...                             ...   \n",
       "22539                       0.06                            0.01   \n",
       "22540                       0.00                            0.01   \n",
       "22541                       0.00                            0.00   \n",
       "22542                       0.01                            0.00   \n",
       "22543                       0.03                            0.00   \n",
       "\n",
       "       37 Dst-host-srv-diff-host-rate  38 Dst-host-serror-rate   \n",
       "0                                0.00                     0.00  \\\n",
       "1                                0.00                     0.00   \n",
       "2                                0.00                     1.00   \n",
       "3                                0.04                     0.03   \n",
       "4                                0.00                     0.00   \n",
       "...                               ...                      ...   \n",
       "22539                            0.01                     0.01   \n",
       "22540                            0.01                     0.01   \n",
       "22541                            0.00                     0.00   \n",
       "22542                            0.00                     0.00   \n",
       "22543                            0.00                     0.00   \n",
       "\n",
       "       39 Dst-host-srv-serror-rate  40 Dst-host-rerror-rate   \n",
       "0                             0.00                     0.05  \\\n",
       "1                             0.00                     0.00   \n",
       "2                             1.00                     0.00   \n",
       "3                             0.01                     0.00   \n",
       "4                             0.00                     0.00   \n",
       "...                            ...                      ...   \n",
       "22539                         0.00                     0.00   \n",
       "22540                         0.00                     0.00   \n",
       "22541                         0.00                     0.07   \n",
       "22542                         0.00                     0.00   \n",
       "22543                         0.00                     0.44   \n",
       "\n",
       "       41 Dst-host-srv-rerror-rate 42 Attack_type  43 Difficulty  \n",
       "0                             0.00         normal             20  \n",
       "1                             0.00         normal             15  \n",
       "2                             0.00        neptune             19  \n",
       "3                             0.01         normal             21  \n",
       "4                             0.00         normal             21  \n",
       "...                            ...            ...            ...  \n",
       "22539                         0.00         normal             21  \n",
       "22540                         0.00         normal             21  \n",
       "22541                         0.07           back             15  \n",
       "22542                         0.00         normal             21  \n",
       "22543                         1.00          mscan             14  \n",
       "\n",
       "[148517 rows x 43 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50dfa5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last column (which might be the difficulty, so it's useless)\n",
    "data.drop('43 Difficulty', inplace=True, axis=1)\n",
    "# Drop the 19th column wich is full of 0, so has std=0. which causes issues for the normalization\n",
    "data.drop('20 Num-outbound-cmds', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "81d01d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the nominal attribute \"Attack type\" into binary (0 : normal / 1 : attack)\n",
    "labels = (data['42 Attack_type'] != 'normal').astype('int64')\n",
    "data['42 Labels'] = labels\n",
    "data.drop('42 Attack_type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9686ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode the 3 first nominal attributes and drop them\n",
    "for i in ['4 Flag : ', '3 Service : ', '2 Protocol-type : ']:\n",
    "    # Create the One Hot Encode DataFrame\n",
    "    dum = pd.get_dummies(data[i])\n",
    "    # Insert into the dataset DataFrame by Series\n",
    "    for column_name in list(dum.columns):\n",
    "        data.insert(1, str(i)+column_name, dum[column_name])\n",
    "        data[str(i)+column_name] = data[str(i)+column_name].astype('int64')\n",
    "    # Drop the old attribute's column\n",
    "    data.drop(i, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3b0dbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test sets\n",
    "df_training = data[:df_training.shape[0]]    \n",
    "df_testing = data[df_training.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "09f46607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing[i] = ((df_testing[i] - min) / (max - min))\n",
      "/tmp/ipykernel_120859/3046827848.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training[i] = ((df_training[i] - min) / (max - min))\n"
     ]
    }
   ],
   "source": [
    "# Min-Max normalization on the non binary features\n",
    "for i in ['1 Duration', '5 Src-bytes', '6 Dst-bytes', '8 Wrong-fragment', '9 Urgent', '10 Hot', '11 Num-failed-logins', '13 Num-compromised', '15 Su-attempted', '16 Num-root', '17 Num-file-creations', '18 Num-shells', '19 Num-access-files', '23 Count', '24 Srv-count', '25 Serror-rate', '26 Srv-serror-rate', '27 Rerror-rate', '28 Srv-rerror-rate', '29 Same-srv-rate', '30 Diff-srv-rate', '31 Srv-diff-host-rate', '32 Dst-host-count', '33 Dst-host-srv-count', '34 Dst-host-same-srv-rate', '35 Dst-host-diff-srv-rate', '36 Dst-host-same-src-port-rate', '37 Dst-host-srv-diff-host-rate', '38 Dst-host-serror-rate', '39 Dst-host-srv-serror-rate', '40 Dst-host-rerror-rate', '41 Dst-host-srv-rerror-rate']:\n",
    "    # The min and max are only computed from the training set\n",
    "    min = df_training[i].min()\n",
    "    max = df_training[i].max()\n",
    "    df_training[i] = ((df_training[i] - min) / (max - min)) \n",
    "    df_testing[i] = ((df_testing[i] - min) / (max - min)) \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "de5ad88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NumPy arrays from DataFrames\n",
    "nd_training = df_training.values\n",
    "nd_testing = df_testing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ce4cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125973, 122), (22544, 122))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_training.shape, nd_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "08239a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 1.  , ..., 0.05, 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , ..., 0.  , 0.  , 1.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 1.  , ..., 0.01, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , ..., 0.  , 0.  , 1.  ],\n",
       "       [0.  , 0.  , 1.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6d06282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating arguments (x) from labelss (y)\n",
    "x_train = nd_training[:, :-1]\n",
    "y_train = nd_training[:, -1]\n",
    "x_test = nd_testing[:, :-1]\n",
    "y_test = nd_testing[:, -1]\n",
    "\n",
    "# Make a copy of the data set as NumPy arrays\n",
    "x_train_np = x_train.copy()\n",
    "y_train_np = y_train.copy()\n",
    "x_test_np = x_test.copy()\n",
    "y_test_np = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2af9f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from numpy array to torch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d68a0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' A basic neural network model '''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()         #python2 : super(MLP, self).__init__()\n",
    "        #defining the network's operations\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], output_size)\n",
    "\n",
    "    def forward(self, x, softmax=False): \n",
    "        a = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x.float())))))\n",
    "        if softmax:\n",
    "            y_pred = F.softmax(a, dim=1)\n",
    "        else:\n",
    "            y_pred = a\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1990ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, real):\n",
    "    ''' Evaluates the accuracy of the predictions'''\n",
    "    n_correct = torch.eq(predictions, real).sum().item()\n",
    "    accuracy = n_correct / len(predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "19993c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on : cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on : {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4541d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size is  121\n"
     ]
    }
   ],
   "source": [
    "# Initialising the model\n",
    "input_size=x_train.shape[1]\n",
    "print('input size is ', input_size)\n",
    "hidden_size=[256,256]\n",
    "output_size=2\n",
    "model = Network(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d8164021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfering model and data to GPU\n",
    "model = model.to(device)\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b0a740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=121, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dca91770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Loss function and Adam learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8037668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model.pytorch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06de80d",
   "metadata": {},
   "source": [
    "# Adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ed8c83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_feat_stats = pd.DataFrame(index=df_training.columns[:-1])\n",
    "\n",
    "adv_results = pd.DataFrame(index=['Accuracy', \n",
    "                                  'Mean perturbed features   [Mean L0]', \n",
    "                                  'Max perturbed features    [Max  L0]', \n",
    "                                  'Mean Euclidiant distance  [Mean L2]', \n",
    "                                  'Max Euclidiant distance   [Max  L2]', \n",
    "                                  'Mean Maximum perturbation [Mean Li]', \n",
    "                                  'Max Maximum perturbation  [Max  Li]'])\n",
    "\n",
    "adv_inv = pd.DataFrame(index=['Invalid value range',\n",
    "                              'Invalid binary values',\n",
    "                              'Invalid class belonging'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "04c09292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_norms(x_test_cpu, adversarial_examples_cpu):\n",
    "    mean_l0 = np.mean(np.sum(x_test_cpu != adversarial_examples_cpu, axis=1))\n",
    "    max_l0 = np.max(np.sum(x_test_cpu != adversarial_examples_cpu, axis=1))\n",
    "    mean_l2 = np.mean(np.sum(np.power(x_test_cpu - adversarial_examples_cpu, 2), axis=1, keepdims=True))\n",
    "    max_l2 = np.max(np.sum(np.power(x_test_cpu - adversarial_examples_cpu, 2), axis=1, keepdims=True))\n",
    "    mean_li = np.mean(np.max(np.abs(x_test_cpu - adversarial_examples_cpu), axis=1, keepdims=True))\n",
    "    max_li = np.max(np.max(np.abs(x_test_cpu - adversarial_examples_cpu), axis=1, keepdims=True))\n",
    "    return [mean_l0, max_l0, mean_l2, max_l2, mean_li, max_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "652b9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_criteria(x_test_cpu, adversarial_examples_cpu):\n",
    "    # Verify value ranges\n",
    "    min = x_test_cpu.min(axis=1, keepdims=True)\n",
    "    max = x_test_cpu.max(axis=1, keepdims=True)\n",
    "    adv_range = (adversarial_examples_cpu < min) | (adversarial_examples_cpu > max)\n",
    "    adv_range = adv_range.any(axis=1, keepdims=True)\n",
    "    adv_range = adv_range.sum(axis=0)\n",
    "    #print(\"proportion of out-of-range values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    # Binary values\n",
    "    binary_feat_ind = list(range(1,85)) + [87, 92, 94, 100, 101]\n",
    "    adv_bin = adversarial_examples_cpu[:, binary_feat_ind]\n",
    "    adv_bin = (adv_bin != 1) & ( adv_bin != 0)\n",
    "    adv_bin = adv_bin.any(axis=1, keepdims=True)\n",
    "    adv_bin = adv_bin.sum(axis=0)\n",
    "    #print(\"proportion of non-binary values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    # Multi class\n",
    "    adv1 = adversarial_examples_cpu[:, 1:4] != 0\n",
    "    adv1 = adv1.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv1 = adv1.sum(axis=1, keepdims=True)\n",
    "\n",
    "    adv2 = adversarial_examples_cpu[:, 4:74] != 0\n",
    "    adv2 = adv2.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv2 = adv2.sum(axis=1, keepdims=True)\n",
    "\n",
    "    adv3 = adversarial_examples_cpu[:, 74:85] != 0\n",
    "    adv3 = adv3.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv3 = adv3.sum(axis=1, keepdims=True)\n",
    "\n",
    "    adv_cat = adv1 | adv2 | adv3\n",
    "    adv_cat = adv_cat.sum(axis=0)\n",
    "    #print(\"proportion of multiple category values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    return [adv_range[0]*100/x_test.shape[0], adv_bin[0]*100/x_test.shape[0], adv_cat[0]*100/x_test.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "44b1cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples = df_testing[df_testing['42 Labels'] == 1].values\n",
    "x_test = torch.from_numpy((positive_examples[:, :-1])).float()\n",
    "y_test = torch.from_numpy((positive_examples[:, -1])).float()\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5a0909ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the PyTorch wrapper\n",
    "classifier = PyTorchClassifier(model=model, loss=criterion, optimizer=optimizer, input_shape=input_size, nb_classes=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "41d00d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.17610847034989\n",
      "Accuracy                               80.176108\n",
      "Mean perturbed features   [Mean L0]     0.000000\n",
      "Max perturbed features    [Max  L0]     0.000000\n",
      "Mean Euclidiant distance  [Mean L2]     0.000000\n",
      "Max Euclidiant distance   [Max  L2]     0.000000\n",
      "Mean Maximum perturbation [Mean Li]     0.000000\n",
      "Max Maximum perturbation  [Max  Li]     0.000000\n",
      "Name: Clean, dtype: float64\n",
      "Invalid value range        0.0\n",
      "Invalid binary values      0.0\n",
      "Invalid class belonging    0.0\n",
      "Name: Clean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The model performance on untouched attack samples.\n",
    "_, predictions_clean = model(x_test, softmax=True).max(dim=1)\n",
    "accuracy_clean = evaluate_predictions(predictions=predictions_clean.long(), real=y_test)\n",
    "print(accuracy_clean)\n",
    "attack='Clean'\n",
    "\n",
    "# Exporting the clean examples in a .xlsx file\n",
    "#excel_writer = pd.ExcelWriter(\"adversarial_examples.xlsx\", engine='openpyxl') \n",
    "#xlsx_export = pd.DataFrame(np.hstack((x_test.cpu().numpy(),y_test.cpu().numpy().reshape(y_test.shape[0], 1))), columns=data.columns)\n",
    "#xlsx_export.to_excel(excel_writer, sheet_name=attack)\n",
    "\n",
    "# Exporting the clean examples in a .csv file\n",
    "pd.DataFrame(np.hstack((x_test.cpu().numpy(),y_test.cpu().numpy().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"clean_examples.csv\")\n",
    "\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "adv_results[attack] = [accuracy_clean] + adv_norms(x_test_cpu, x_test_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, x_test_cpu)\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497f395",
   "metadata": {},
   "source": [
    "# Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e486d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.8087%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.52     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.52     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.808696\n",
      "Mean perturbed features   [Mean L0]    103.030312\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      1.030303\n",
      "Max Euclidiant distance   [Max  L2]      1.209999\n",
      "Mean Maximum perturbation [Mean Li]      0.085187\n",
      "Max Maximum perturbation  [Max  Li]      0.100000\n",
      "Name: FGSM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: FGSM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adversarial_crafter = FastGradientMethod(classifier,\n",
    "                                         norm=np.inf,\n",
    "                                         eps=0.1,\n",
    "                                         targeted=False,\n",
    "                                         num_random_init=0,\n",
    "                                         batch_size=128,\n",
    "                                         )\n",
    "\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'FGSM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_FGSM1.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9ab7445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.9568%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.52     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.52     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.956752\n",
      "Mean perturbed features   [Mean L0]    103.030312\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      4.121210\n",
      "Max Euclidiant distance   [Max  L2]      4.839997\n",
      "Mean Maximum perturbation [Mean Li]      0.170373\n",
      "Max Maximum perturbation  [Max  Li]      0.200000\n",
      "Name: FGSM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: FGSM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adversarial_crafter = FastGradientMethod(classifier,\n",
    "                                         norm=np.inf,\n",
    "                                         eps=0.2,\n",
    "                                         targeted=False,\n",
    "                                         num_random_init=0,\n",
    "                                         batch_size=128,\n",
    "                                         )\n",
    "\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'FGSM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_FGSM2.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "67e0873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.9568%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.52     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.52     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.956752\n",
      "Mean perturbed features   [Mean L0]    103.030312\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      9.272736\n",
      "Max Euclidiant distance   [Max  L2]     10.890010\n",
      "Mean Maximum perturbation [Mean Li]      0.255560\n",
      "Max Maximum perturbation  [Max  Li]      0.300000\n",
      "Name: FGSM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: FGSM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adversarial_crafter = FastGradientMethod(classifier,\n",
    "                                         norm=np.inf,\n",
    "                                         eps=0.3,\n",
    "                                         targeted=False,\n",
    "                                         num_random_init=0,\n",
    "                                         batch_size=128,\n",
    "                                         )\n",
    "\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'FGSM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_FGSM3.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ed4fcd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 35.1827%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.52     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.18      0.26     12833\n",
      "weighted avg       1.00      0.35      0.52     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                35.182732\n",
      "Mean perturbed features   [Mean L0]    103.030312\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.257576\n",
      "Max Euclidiant distance   [Max  L2]      0.302500\n",
      "Mean Maximum perturbation [Mean Li]      0.042593\n",
      "Max Maximum perturbation  [Max  Li]      0.050000\n",
      "Name: FGSM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: FGSM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adversarial_crafter = FastGradientMethod(classifier,\n",
    "                                         norm=np.inf,\n",
    "                                         eps=0.05,\n",
    "                                         targeted=False,\n",
    "                                         num_random_init=0,\n",
    "                                         batch_size=128,\n",
    "                                         )\n",
    "\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'FGSM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_FGSM4.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be01d8",
   "metadata": {},
   "source": [
    "# BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "febe1584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c0df34e813441ca177ec35f0895265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    103.043871\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.242522\n",
      "Max Euclidiant distance   [Max  L2]      0.302500\n",
      "Mean Maximum perturbation [Mean Li]      0.042593\n",
      "Max Maximum perturbation  [Max  Li]      0.050000\n",
      "Name: BIM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: BIM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#BIM\n",
    "adversarial_crafter = BasicIterativeMethod(classifier, \n",
    "                                           eps=0.05, \n",
    "                                           eps_step=0.001,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'BIM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .xlsx file\n",
    "#xlsx_export = pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns)\n",
    "#xlsx_export['Adversarial prediction'] = predictions_adv.cpu().numpy().reshape(y_test.shape[0], 1)\n",
    "#xlsx_export.to_excel(excel_writer, sheet_name=attack)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_BIM1.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "88070b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caee7cef56c249dc8d0dfa7311f8afcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    103.046988\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.861515\n",
      "Max Euclidiant distance   [Max  L2]      1.171971\n",
      "Mean Maximum perturbation [Mean Li]      0.085187\n",
      "Max Maximum perturbation  [Max  Li]      0.100000\n",
      "Name: BIM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: BIM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#BIM\n",
    "adversarial_crafter = BasicIterativeMethod(classifier, \n",
    "                                           eps=0.1, \n",
    "                                           eps_step=0.001,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'BIM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_BIM2.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2949ba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910135c080414b3ebc04752d33d374de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    103.046988\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.861516\n",
      "Max Euclidiant distance   [Max  L2]      1.171974\n",
      "Mean Maximum perturbation [Mean Li]      0.085189\n",
      "Max Maximum perturbation  [Max  Li]      0.100005\n",
      "Name: BIM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: BIM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#BIM\n",
    "adversarial_crafter = BasicIterativeMethod(classifier, \n",
    "                                           eps=0.2, \n",
    "                                           eps_step=0.001,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'BIM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_BIM3.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d3862983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349009526ffd4c488659c8d6f5111d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    103.046988\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.861516\n",
      "Max Euclidiant distance   [Max  L2]      1.171974\n",
      "Mean Maximum perturbation [Mean Li]      0.085189\n",
      "Max Maximum perturbation  [Max  Li]      0.100005\n",
      "Name: BIM, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: BIM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#BIM\n",
    "adversarial_crafter = BasicIterativeMethod(classifier, \n",
    "                                           eps=0.3, \n",
    "                                           eps_step=0.001,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'BIM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_BIM4.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4510930",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "297611c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fd9331c3074cde9ecf3085c32f67d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    102.656511\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      0.253195\n",
      "Max Euclidiant distance   [Max  L2]      0.302500\n",
      "Mean Maximum perturbation [Mean Li]      0.042593\n",
      "Max Maximum perturbation  [Max  Li]      0.050000\n",
      "Name: PGD, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: PGD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PGD \n",
    "adversarial_crafter = ProjectedGradientDescent(classifier, \n",
    "                                           eps=0.05,\n",
    "                                        norm = 'inf', \n",
    "                                           eps_step=0.01,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'PGD'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .xlsx file\n",
    "#xlsx_export = pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns)\n",
    "#xlsx_export['Adversarial prediction'] = predictions_adv.cpu().numpy().reshape(y_test.shape[0], 1)\n",
    "#xlsx_export.to_excel(excel_writer, sheet_name=attack)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_PGD1.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7a0657b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083e2e72e7db4554a989460fd0cf3a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    102.910076\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      1.015563\n",
      "Max Euclidiant distance   [Max  L2]      1.209999\n",
      "Mean Maximum perturbation [Mean Li]      0.085187\n",
      "Max Maximum perturbation  [Max  Li]      0.100000\n",
      "Name: PGD, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: PGD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PGD \n",
    "adversarial_crafter = ProjectedGradientDescent(classifier, \n",
    "                                           eps=0.1,\n",
    "                                        norm = 'inf', \n",
    "                                           eps_step=0.01,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'PGD'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_PGD2.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5dd1edfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6705c70173b24142b4b79b17e9c51c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    102.959713\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      4.042997\n",
      "Max Euclidiant distance   [Max  L2]      4.839997\n",
      "Mean Maximum perturbation [Mean Li]      0.170373\n",
      "Max Maximum perturbation  [Max  Li]      0.200000\n",
      "Name: PGD, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: PGD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PGD \n",
    "adversarial_crafter = ProjectedGradientDescent(classifier, \n",
    "                                           eps=0.2,\n",
    "                                        norm = 'inf', \n",
    "                                           eps_step=0.01,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'PGD'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_PGD3.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "39a7acb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87162a533e9a4ff4b41a1a8a243ac6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 34.6373%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.35      0.51     12833\n",
      "\n",
      "    accuracy                           0.35     12833\n",
      "   macro avg       0.50      0.17      0.26     12833\n",
      "weighted avg       1.00      0.35      0.51     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                34.637263\n",
      "Mean perturbed features   [Mean L0]    103.025092\n",
      "Max perturbed features    [Max  L0]    121.000000\n",
      "Mean Euclidiant distance  [Mean L2]      9.057258\n",
      "Max Euclidiant distance   [Max  L2]     10.890010\n",
      "Mean Maximum perturbation [Mean Li]      0.255560\n",
      "Max Maximum perturbation  [Max  Li]      0.300000\n",
      "Name: PGD, dtype: float64\n",
      "Invalid value range        85.186628\n",
      "Invalid binary values      85.186628\n",
      "Invalid class belonging    85.186628\n",
      "Name: PGD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PGD \n",
    "adversarial_crafter = ProjectedGradientDescent(classifier, \n",
    "                                           eps=0.3,\n",
    "                                        norm = 'inf', \n",
    "                                           eps_step=0.01,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'PGD'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_PGD4.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad339e7",
   "metadata": {},
   "source": [
    "# CW L_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4bf5f40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c46c6425de4528880099023f2aa11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 18.1485%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.18      0.31     12833\n",
      "\n",
      "    accuracy                           0.18     12833\n",
      "   macro avg       0.50      0.09      0.15     12833\n",
      "weighted avg       1.00      0.18      0.31     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                               18.148523\n",
      "Mean perturbed features   [Mean L0]    14.014026\n",
      "Max perturbed features    [Max  L0]    22.000000\n",
      "Mean Euclidiant distance  [Mean L2]     1.668435\n",
      "Max Euclidiant distance   [Max  L2]     9.485065\n",
      "Mean Maximum perturbation [Mean Li]     0.577300\n",
      "Max Maximum perturbation  [Max  Li]     1.494115\n",
      "Name: CW2, dtype: float64\n",
      "Invalid value range        96.571340\n",
      "Invalid binary values      99.992208\n",
      "Invalid class belonging     0.000000\n",
      "Name: CW2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL2Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.01,\n",
    "                                      binary_search_steps=10,\n",
    "                                      max_iter=10,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'CW2'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_CW21.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4f325186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f425e96c5cb7483aa87520e30e6f8c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 18.0784%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.18      0.31     12833\n",
      "\n",
      "    accuracy                           0.18     12833\n",
      "   macro avg       0.50      0.09      0.15     12833\n",
      "weighted avg       1.00      0.18      0.31     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                               18.078392\n",
      "Mean perturbed features   [Mean L0]    14.001013\n",
      "Max perturbed features    [Max  L0]    22.000000\n",
      "Mean Euclidiant distance  [Mean L2]     1.695928\n",
      "Max Euclidiant distance   [Max  L2]    10.695344\n",
      "Mean Maximum perturbation [Mean Li]     0.583645\n",
      "Max Maximum perturbation  [Max  Li]     1.829102\n",
      "Name: CW2, dtype: float64\n",
      "Invalid value range         96.134965\n",
      "Invalid binary values      100.000000\n",
      "Invalid class belonging      0.000000\n",
      "Name: CW2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL2Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.1,\n",
    "                                      binary_search_steps=10,\n",
    "                                      max_iter=10,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'CW2'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_CW22.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8026ff38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00701c5d5df485ba3befc438fc9b143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 17.5173%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.18      0.30     12833\n",
      "\n",
      "    accuracy                           0.18     12833\n",
      "   macro avg       0.50      0.09      0.15     12833\n",
      "weighted avg       1.00      0.18      0.30     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                               17.517338\n",
      "Mean perturbed features   [Mean L0]    14.045741\n",
      "Max perturbed features    [Max  L0]    22.000000\n",
      "Mean Euclidiant distance  [Mean L2]     1.618345\n",
      "Max Euclidiant distance   [Max  L2]     9.485065\n",
      "Mean Maximum perturbation [Mean Li]     0.567012\n",
      "Max Maximum perturbation  [Max  Li]     1.494115\n",
      "Name: CW2, dtype: float64\n",
      "Invalid value range        96.516793\n",
      "Invalid binary values      99.992208\n",
      "Invalid class belonging     0.000000\n",
      "Name: CW2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL2Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.01,\n",
    "                                      binary_search_steps=20,\n",
    "                                      max_iter=20,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'CW2'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_CW23.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "63346c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd98c1e2259f457cb942bf78b9f559e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 80.1761%\n",
      "Final Testing Accuracy : 15.6783%\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.16      0.27     12833\n",
      "\n",
      "    accuracy                           0.16     12833\n",
      "   macro avg       0.50      0.08      0.14     12833\n",
      "weighted avg       1.00      0.16      0.27     12833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/virtual environments/adv detection by robustness/adv_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                               15.678329\n",
      "Mean perturbed features   [Mean L0]    14.098496\n",
      "Max perturbed features    [Max  L0]    22.000000\n",
      "Mean Euclidiant distance  [Mean L2]     1.618843\n",
      "Max Euclidiant distance   [Max  L2]     6.939663\n",
      "Mean Maximum perturbation [Mean Li]     0.563087\n",
      "Max Maximum perturbation  [Max  Li]     1.359501\n",
      "Name: CW2, dtype: float64\n",
      "Invalid value range        96.212889\n",
      "Invalid binary values      99.968830\n",
      "Invalid class belonging     0.000000\n",
      "Name: CW2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL2Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.1,\n",
    "                                      binary_search_steps=10,\n",
    "                                      max_iter=100,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=np.array(x_test.cpu()))\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate_predictions(predictions=predictions_adv.long(), real=y_test)\n",
    "\n",
    "attack = 'CW2'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), \n",
    "             columns=data.columns).to_csv(\"adversarial_examples_CW24.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80fbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
