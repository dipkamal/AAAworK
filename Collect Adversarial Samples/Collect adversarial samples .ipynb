{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3ed422",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to collect adversarial samples for each dataset for varying attack parameters and save them as numpy arrays so that we can use them by loading as numpy files easily for later experiments. Saves a lot of time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ba3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "import gc\n",
    "from captum.attr import *\n",
    "import quantus\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "from art.attacks.evasion import CarliniLInfMethod\n",
    "import torch.optim as optim\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde97d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398c2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa54425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dcb89",
   "metadata": {},
   "source": [
    "# Various attack functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e60368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pgd_attack(x_batch, y_batch, eps, normal_model): \n",
    "    \n",
    "    alpha = eps/10\n",
    "    steps = 40\n",
    "    images_pgd = projected_gradient_descent(normal_model, x_batch, eps, alpha, steps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adafb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fgsm_attack(x_batch, y_batch, eps, normal_model): \n",
    "    images_pgd = fast_gradient_method(normal_model, x_batch, eps, np.inf)\n",
    "    _, y_pred_pgd = normal_model(images_pgd).max(1)\n",
    "    index = (y_pred_pgd != y_batch)\n",
    "    pgd_images = images_pgd[index]\n",
    "    y_pred_pgd = y_pred_pgd[index]\n",
    "    return pgd_images, y_pred_pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b75cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_linf_attack(model, images, labels, epsilon, confidence, num_iterations, learning_rate):\n",
    "    batch_size = images.size(0)\n",
    "    image_size = images.size(2)\n",
    "    num_classes = model(images).size(1)\n",
    "\n",
    "    # Define the box constraints for the adversarial perturbation\n",
    "    box_min = torch.clamp(images - epsilon, min=0)\n",
    "    box_max = torch.clamp(images + epsilon, max=1)\n",
    "\n",
    "    # Initialize the adversarial perturbation as a small random noise\n",
    "    perturbation = torch.zeros_like(images).uniform_(-epsilon, epsilon).to(images.device)\n",
    "    perturbation.requires_grad = True\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam([perturbation], lr=learning_rate)\n",
    "\n",
    "    # Perform optimization to find the adversarial perturbation\n",
    "    for _ in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Create adversarial images with perturbation\n",
    "        images_adv = torch.clamp(images + perturbation, min=0, max=1)\n",
    "\n",
    "        # Compute the model's logits for the adversarial images\n",
    "        outputs = model(images_adv)\n",
    "\n",
    "        # Compute the adversarial loss\n",
    "        real_logits = outputs.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
    "        other_logits = outputs - torch.eye(num_classes).to(images.device)[labels].unsqueeze(1)\n",
    "        max_other_logits, _ = other_logits.max(1)\n",
    "        adversarial_loss = torch.max(torch.zeros_like(real_logits), max_other_logits - real_logits + confidence)\n",
    "\n",
    "        # Compute the total loss as a combination of adversarial loss and L-infinity norm\n",
    "        total_loss = adversarial_loss.mean() + torch.norm(perturbation.view(batch_size, -1), p=float('inf'), dim=1).mean()\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Project the perturbation back into the L-infinity box constraints\n",
    "        perturbation.data = torch.max(torch.min(perturbation.detach(), box_max - images), box_min - images)\n",
    "\n",
    "    # Create adversarial images with the final perturbation\n",
    "    images_adv = torch.clamp(images + perturbation, min=0, max=1)\n",
    "    \n",
    "    return images_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c591d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cw_attack(model, images, labels, epsilon, confidence, num_iterations, learning_rate):\n",
    "    \n",
    "    x_adv = cw_linf_attack(model, images, labels, epsilon, confidence, num_iterations, learning_rate)\n",
    "    _, y_test = model(x_adv).max(1)\n",
    "    index = (y_test != labels)\n",
    "    adv_images = x_adv[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1aba1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bim_attack(images, labels, eps, model):\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    adv_images = images.clone().detach()\n",
    "    \n",
    "    alpha = eps/10\n",
    "    iters = 10\n",
    "        \n",
    "    for i in range(iters):    \n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        \n",
    "        #calculate loss \n",
    "        cost = loss(outputs, labels)\n",
    "        \n",
    "        #update adversarial images\n",
    "        grad = torch.autograd.grad(cost, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha*grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n",
    "        \n",
    "       \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432b3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bim_attack(x_batch, y_batch, eps, normal_model):\n",
    "    x_test = bim_attack(x_batch, y_batch, eps, normal_model)\n",
    "    #convert the nd array back to tensor\n",
    "    _, y_test = normal_model(x_test).max(1)\n",
    "    index = (y_test != y_batch)\n",
    "    adv_images = x_test[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd232a",
   "metadata": {},
   "source": [
    "## Attack on CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d8ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rev2.cifar10.model_utils import resnet50, CIFAR10_RESNET50_CKPT_PATH\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, out_keys=None):\n",
    "        out = {}\n",
    "        x = self.conv1(x)\n",
    "        out[\"c1\"] = x\n",
    "        x = self.bn1(x)\n",
    "        out[\"bn1\"] = x\n",
    "        x = F.relu(x)\n",
    "        out[\"r1\"] = x\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        out[\"l1\"] = x\n",
    "        x = self.layer2(x)\n",
    "        out[\"l2\"] = x\n",
    "        x = self.layer3(x)\n",
    "        out[\"l3\"] = x\n",
    "        x = self.layer4(x)\n",
    "        out[\"l4\"] = x\n",
    "\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        out[\"gvp\"] = x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        out[\"fc\"] = x\n",
    "\n",
    "        if out_keys is None:\n",
    "            return x\n",
    "        res = {}\n",
    "        for key in out_keys:\n",
    "            res[key] = out[key]\n",
    "        return res\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1,3,32,32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4b2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_model(path):\n",
    "    model = resnet50()\n",
    "    ckpt_dict = torch.load(path, lambda storage, loc: storage)\n",
    "    model.load_state_dict(ckpt_dict)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0419eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/Models/CIFAR10/resnet50/cifar.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326ef7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_cifar_model(modelpath)\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5600bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#save image as np arrays \n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_loader_cifar = DataLoader(testset, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8863767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for FGSM\n",
      "700\n",
      "900\n",
      "Saving adversarial images for 0.06274509803921569 for FGSM\n",
      "200\n",
      "300\n",
      "350\n",
      "550\n",
      "700\n",
      "750\n",
      "Saving adversarial images for 0.12549019607843137 for FGSM\n",
      "100\n",
      "250\n",
      "350\n",
      "400\n",
      "800\n",
      "900\n",
      "Saving adversarial images for 0.25098039215686274 for FGSM\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "def compute_fgsm_cifar(train_loader_cifar, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for FGSM\".format(eps))\n",
    "\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    \n",
    "    check = 0\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check += len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if (check %50 == 0):\n",
    "            print(check)\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "\n",
    "\n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "\n",
    "#compute adv samples\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/CIFAR/FGSM/'\n",
    "for eps in epsilons: \n",
    "    compute_fgsm_cifar(test_loader_cifar, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229a896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for PGD\n",
      "350\n",
      "400\n",
      "650\n",
      "Saving adversarial images for 0.06274509803921569 for PGD\n",
      "200\n",
      "Saving adversarial images for 0.12549019607843137 for PGD\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.25098039215686274 for PGD\n"
     ]
    }
   ],
   "source": [
    "def compute_pgd_cifar(train_loader_cifar, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for PGD\".format(eps))\n",
    "\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    \n",
    "    check = 0\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_pgd_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if (check %50 == 0):\n",
    "            print(check)\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "#launch attack\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/CIFAR/PGD/'\n",
    "for eps in epsilons: \n",
    "    compute_pgd_cifar(test_loader_cifar, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30127bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.06274509803921569 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.12549019607843137 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.25098039215686274 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def compute_bim_cifar(train_loader_cifar, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for BIM\".format(eps))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    \n",
    "    check = 0\n",
    "\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_bim_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if (check %50 == 0):\n",
    "            print(check)\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "\n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "    \n",
    "#launch attack\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/CIFAR/BIM/'\n",
    "for eps in epsilons: \n",
    "    compute_bim_cifar(test_loader_cifar, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5205769c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for eps 0.15 and confidence 0 for CW\n",
      "50\n",
      "500\n",
      "950\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def compute_cw_cifar(train_loader_cifar, normal_model, eps, conf, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for eps {} and confidence {} for CW\".format(eps, conf))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    \n",
    "    num_iterations = 400\n",
    "    learning_rate = 0.01\n",
    "    check=0\n",
    "        \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader_cifar):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        images_adv,y_pred_adv = make_cw_attack(normal_model, x_batch, y_batch, eps, conf, num_iterations, learning_rate)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        \n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        \n",
    "        if (check)%50==0:\n",
    "            print((check)) \n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)  \n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "   \n",
    "    \n",
    "#launch attack\n",
    "confidence = [0]\n",
    "epsilons = 0.15\n",
    "save_dir = 'adv samples/CIFAR/CW/'\n",
    "for conf in confidence: \n",
    "    compute_cw_cifar(test_loader_cifar, normal_model, epsilons, conf, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0ccf9",
   "metadata": {},
   "source": [
    "## Attack on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39eb085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet_normal(torch.nn.Module):\n",
    "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473acc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_model(path):\n",
    "    model = LeNet_normal()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9589bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"/data/virtual environments/adv detection by robustness/adv_detection/Adaptive attacks/Models/MNIST/mnist_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21b43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet_normal(\n",
       "  (conv_1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu_2): ReLU()\n",
       "  (fc_1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu_4): ReLU()\n",
       "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_mnist_model(modelpath)\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c878a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.MNIST(root='./sample_data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f44331f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for FGSM\n",
      "100\n",
      "200\n",
      "250\n",
      "250\n",
      "300\n",
      "350\n",
      "350\n",
      "400\n",
      "450\n",
      "450\n",
      "450\n",
      "500\n",
      "500\n",
      "550\n",
      "550\n",
      "550\n",
      "650\n",
      "750\n",
      "750\n",
      "800\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.06274509803921569 for FGSM\n",
      "150\n",
      "300\n",
      "550\n",
      "600\n",
      "Saving adversarial images for 0.12549019607843137 for FGSM\n",
      "100\n",
      "350\n",
      "Saving adversarial images for 0.25098039215686274 for FGSM\n",
      "100\n",
      "300\n",
      "350\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "def compute_fgsm(train_loader, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for FGSM\".format(eps))\n",
    "\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0\n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if check % 50 == 0:\n",
    "            print(check)\n",
    "\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "\n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "#compute adv samples\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/MNIST/FGSM/'\n",
    "for eps in epsilons: \n",
    "    compute_fgsm(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adfce63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for PGD\n",
      "150\n",
      "600\n",
      "750\n",
      "750\n",
      "800\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.06274509803921569 for PGD\n",
      "100\n",
      "550\n",
      "850\n",
      "Saving adversarial images for 0.12549019607843137 for PGD\n",
      "150\n",
      "350\n",
      "400\n",
      "850\n",
      "Saving adversarial images for 0.25098039215686274 for PGD\n"
     ]
    }
   ],
   "source": [
    "def compute_pgd(train_loader, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for PGD\".format(eps))\n",
    "\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_pgd_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if check % 50 == 0:\n",
    "            print(check)\n",
    "\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "\n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "    \n",
    "#launch attack\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/MNIST/PGD/'\n",
    "for eps in epsilons: \n",
    "    compute_pgd(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34cc6b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for BIM\n",
      "50\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "250\n",
      "250\n",
      "300\n",
      "300\n",
      "300\n",
      "350\n",
      "350\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "450\n",
      "550\n",
      "550\n",
      "650\n",
      "800\n",
      "850\n",
      "850\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "Saving adversarial images for 0.06274509803921569 for BIM\n",
      "50\n",
      "100\n",
      "250\n",
      "550\n",
      "600\n",
      "700\n",
      "700\n",
      "900\n",
      "Saving adversarial images for 0.12549019607843137 for BIM\n",
      "150\n",
      "500\n",
      "600\n",
      "Saving adversarial images for 0.25098039215686274 for BIM\n",
      "150\n",
      "550\n",
      "700\n",
      "850\n"
     ]
    }
   ],
   "source": [
    "def compute_bim(train_loader, normal_model, eps, save_dir):\n",
    "\n",
    "    print(\"Saving adversarial images for {} for BIM\".format(eps))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #create adv samples\n",
    "        images_adv,y_pred_adv = make_bim_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "\n",
    "        if check % 50 == 0:\n",
    "            print(check)\n",
    "\n",
    "        if check > 1000:\n",
    "            break\n",
    "\n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "\n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "    \n",
    "#launch attack\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/MNIST/BIM/'\n",
    "for eps in epsilons: \n",
    "    compute_bim(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1210c86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for eps 0.15 and confidence 0 for CW\n",
      "0\n",
      "50\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "400\n",
      "450\n",
      "450\n",
      "450\n",
      "450\n",
      "450\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "750\n",
      "750\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "850\n",
      "850\n",
      "850\n",
      "900\n",
      "900\n",
      "900\n",
      "950\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def compute_cw(train_loader, normal_model, eps, conf, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for eps {} and confidence {} for CW\".format(eps, conf))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    \n",
    "    num_iterations = 400\n",
    "    learning_rate = 0.01\n",
    "    check=0\n",
    "        \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        images_adv,y_pred_adv = make_cw_attack(normal_model, x_batch, y_batch, eps, conf, num_iterations, learning_rate)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        \n",
    "        if (check)%50==0:\n",
    "            print((check)) \n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(conf)+str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "    \n",
    "#launch attack\n",
    "confidence = [0]\n",
    "epsilons = 0.15\n",
    "save_dir = 'adv samples/MNIST/CW/'\n",
    "for conf in confidence: \n",
    "    compute_cw(test_loader, normal_model, epsilons, conf, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd217573",
   "metadata": {},
   "source": [
    "## Attack on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be45f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "372ea884",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = '/home/db1702/Downloads/imagenet-mini/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b124c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_imagenet_model():\n",
    "#     model = models.resnet50(pretrained=True).to(device)\n",
    "#     model.to('cuda')\n",
    "#     model.train(False)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74ea6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_model():\n",
    "    model=torchvision.models.mobilenet_v3_small(weights=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb871eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "test = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "test_loader = DataLoader(test, shuffle=True, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cbc9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for FGSM\n",
      "100\n",
      "150\n",
      "300\n",
      "400\n",
      "550\n",
      "650\n",
      "700\n",
      "800\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.06274509803921569 for FGSM\n",
      "100\n",
      "200\n",
      "250\n",
      "350\n",
      "400\n",
      "500\n",
      "550\n",
      "650\n",
      "750\n",
      "800\n",
      "Saving adversarial images for 0.12549019607843137 for FGSM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "550\n",
      "700\n",
      "850\n",
      "900\n",
      "1000\n",
      "Saving adversarial images for 0.25098039215686274 for FGSM\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "600\n",
      "650\n",
      "700\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "def compute_fgsm(train_loader, normal_model, eps, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for {} for FGSM\".format(eps))\n",
    "    \n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0 \n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_fgsm_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        if check%50==0:\n",
    "            print(check)\n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "#compute adv samples\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/IMAGENET/MobileNet/FGSM/'\n",
    "for eps in epsilons: \n",
    "    compute_fgsm(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bb2465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for PGD\n",
      "50\n",
      "100\n",
      "150\n",
      "250\n",
      "300\n",
      "450\n",
      "500\n",
      "650\n",
      "750\n",
      "800\n",
      "950\n",
      "Saving adversarial images for 0.06274509803921569 for PGD\n",
      "100\n",
      "200\n",
      "300\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "750\n",
      "850\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.12549019607843137 for PGD\n",
      "100\n",
      "300\n",
      "400\n",
      "500\n",
      "550\n",
      "600\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "1000\n",
      "Saving adversarial images for 0.25098039215686274 for PGD\n",
      "150\n",
      "200\n",
      "250\n",
      "350\n",
      "550\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "def compute_pgd(train_loader, normal_model, eps, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for {} for PGD\".format(eps))\n",
    "    \n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0 \n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_pgd_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        if check%50==0:\n",
    "            print(check)\n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "#compute adv samples\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/IMAGENET/MobileNet/PGD/'\n",
    "for eps in epsilons: \n",
    "    compute_pgd(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec2c033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for 0.03137254901960784 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.06274509803921569 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.12549019607843137 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "Saving adversarial images for 0.25098039215686274 for BIM\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def compute_bim(train_loader, normal_model, eps, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for {} for BIM\".format(eps))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0 \n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #create adv samples    \n",
    "        images_adv,y_pred_adv = make_bim_attack(x_batch, y_batch, eps, normal_model)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        if check%50==0:\n",
    "            print(check)\n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "    \n",
    "#launch attack\n",
    "epsilons = [8/255, 16/255, 32/255, 64/255]\n",
    "save_dir = 'adv samples/IMAGENET/MobileNet/BIM/'\n",
    "for eps in epsilons: \n",
    "    compute_bim(test_loader, normal_model, eps, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48d633cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "def imagenet_cw_linf_attack(images, labels, model, epsilon=0.3, confidence=0, max_iterations=400, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Implements the CW-Linf (Carlini-Wagner with L-infinity norm) attack on the ImageNet dataset.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Batch of input images.\n",
    "        labels (torch.Tensor): Corresponding labels for the input images.\n",
    "        model: The model to be attacked. It should return logits (pre-softmax outputs).\n",
    "        epsilon (float): Maximum perturbation allowed (default: 0.03).\n",
    "        confidence (int): Confidence parameter for the attack (default: 0).\n",
    "        max_iterations (int): Maximum number of iterations for the attack (default: 1000).\n",
    "        learning_rate (float): Learning rate for the attack (default: 0.01).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Perturbed images.\n",
    "    \"\"\"\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Clone the original images\n",
    "    perturbed_images = images.clone().detach()\n",
    "\n",
    "    # Iterate for the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        # Zero out the gradients\n",
    "        perturbed_images.requires_grad_(True)\n",
    "\n",
    "        # Calculate the logits for the current perturbed images\n",
    "        logits = model(perturbed_images)\n",
    "\n",
    "        # Calculate the loss (CW-Linf objective function)\n",
    "        correct_logits = logits.gather(1, labels.unsqueeze(1)).squeeze()\n",
    "        wrong_logits = logits - logits.max(dim=1, keepdim=True)[0]\n",
    "        target_logits = wrong_logits.max(dim=1)[0]\n",
    "        loss = torch.max(correct_logits - target_logits + confidence, torch.zeros_like(target_logits))\n",
    "\n",
    "        # Compute the gradients of the loss with respect to the input images\n",
    "        gradients = torch.autograd.grad(loss.sum(), perturbed_images)[0]\n",
    "\n",
    "        # Normalize the gradients (L-infinity norm)\n",
    "        gradients = gradients.sign()\n",
    "\n",
    "        # Update the perturbed images using the gradients\n",
    "        perturbed_images = perturbed_images + learning_rate * gradients\n",
    "\n",
    "        # Clip the perturbed images to ensure they stay within the epsilon ball\n",
    "        perturbed_images = torch.clamp(perturbed_images, images - epsilon, images + epsilon)\n",
    "        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "\n",
    "    return perturbed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aaa3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_make_cw_attack(images, labels, model,epsilon, confidence, num_iterations, learning_rate):\n",
    "    \n",
    "    x_adv = imagenet_cw_linf_attack(images, labels, model, epsilon, confidence, num_iterations, learning_rate)\n",
    "    _, y_test = model(x_adv).max(1)\n",
    "    index = (y_test != labels)\n",
    "    adv_images = x_adv[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eda0939e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for eps 0.15 and confidence 0 for CW\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "450\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "550\n",
      "550\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "800\n",
      "850\n",
      "850\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "950\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def compute_cw(train_loader, normal_model, eps, conf, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for eps {} and confidence {} for CW\".format(eps, conf))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0\n",
    "    \n",
    "    num_iterations = 400\n",
    "    learning_rate = 0.01\n",
    "    check=0\n",
    "        \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        #print(x_batch.shape)\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        images_adv,y_pred_adv = imagenet_make_cw_attack(x_batch, y_batch,normal_model, eps, conf, num_iterations, learning_rate)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        if (check)%50==0:\n",
    "            print((check)) \n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "    \n",
    "    \n",
    "#launch attack\n",
    "confidence = [0]\n",
    "epsilons = 0.15\n",
    "save_dir = 'adv samples/IMAGENET/MobileNet/CW/'\n",
    "for conf in confidence: \n",
    "    compute_cw(test_loader, normal_model, epsilons, conf, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89d017bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a17c4b8b",
   "metadata": {},
   "source": [
    "# cw images resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35445196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dde06052",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = '/home/db1702/Downloads/imagenet-mini/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a73b85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_model():\n",
    "    model = models.resnet50(pretrained=True).to(device)\n",
    "    model.to('cuda')\n",
    "    model.train(False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7966f361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model = load_imagenet_model()\n",
    "normal_model.to(device)\n",
    "normal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cee554a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset\n",
    "test = torchvision.datasets.ImageFolder(images, transform=valid_transform)\n",
    "test_loader = DataLoader(test, shuffle=True, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d15d7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "def imagenet_cw_linf_attack(images, labels, model, epsilon=0.3, confidence=0, max_iterations=400, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Implements the CW-Linf (Carlini-Wagner with L-infinity norm) attack on the ImageNet dataset.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Batch of input images.\n",
    "        labels (torch.Tensor): Corresponding labels for the input images.\n",
    "        model: The model to be attacked. It should return logits (pre-softmax outputs).\n",
    "        epsilon (float): Maximum perturbation allowed (default: 0.03).\n",
    "        confidence (int): Confidence parameter for the attack (default: 0).\n",
    "        max_iterations (int): Maximum number of iterations for the attack (default: 1000).\n",
    "        learning_rate (float): Learning rate for the attack (default: 0.01).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Perturbed images.\n",
    "    \"\"\"\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Clone the original images\n",
    "    perturbed_images = images.clone().detach()\n",
    "\n",
    "    # Iterate for the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        # Zero out the gradients\n",
    "        perturbed_images.requires_grad_(True)\n",
    "\n",
    "        # Calculate the logits for the current perturbed images\n",
    "        logits = model(perturbed_images)\n",
    "\n",
    "        # Calculate the loss (CW-Linf objective function)\n",
    "        correct_logits = logits.gather(1, labels.unsqueeze(1)).squeeze()\n",
    "        wrong_logits = logits - logits.max(dim=1, keepdim=True)[0]\n",
    "        target_logits = wrong_logits.max(dim=1)[0]\n",
    "        loss = torch.max(correct_logits - target_logits + confidence, torch.zeros_like(target_logits))\n",
    "\n",
    "        # Compute the gradients of the loss with respect to the input images\n",
    "        gradients = torch.autograd.grad(loss.sum(), perturbed_images)[0]\n",
    "\n",
    "        # Normalize the gradients (L-infinity norm)\n",
    "        gradients = gradients.sign()\n",
    "\n",
    "        # Update the perturbed images using the gradients\n",
    "        perturbed_images = perturbed_images + learning_rate * gradients\n",
    "\n",
    "        # Clip the perturbed images to ensure they stay within the epsilon ball\n",
    "        perturbed_images = torch.clamp(perturbed_images, images - epsilon, images + epsilon)\n",
    "        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "\n",
    "    return perturbed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "219ed181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_make_cw_attack(images, labels, model,epsilon, confidence, num_iterations, learning_rate):\n",
    "    \n",
    "    x_adv = imagenet_cw_linf_attack(images, labels, model, epsilon, confidence, num_iterations, learning_rate)\n",
    "    _, y_test = model(x_adv).max(1)\n",
    "    index = (y_test != labels)\n",
    "    adv_images = x_adv[index]\n",
    "    y_pred_adv = y_test[index]\n",
    "    return adv_images, y_pred_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79d33e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving adversarial images for eps 0.15 and confidence 0 for CW\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "150\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "450\n",
      "450\n",
      "450\n",
      "450\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "550\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "600\n",
      "650\n",
      "650\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "750\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "850\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "def compute_cw(train_loader, normal_model, eps, conf, save_dir): \n",
    "    \n",
    "    print(\"Saving adversarial images for eps {} and confidence {} for CW\".format(eps, conf))\n",
    "    adversarial_images = []\n",
    "    adversarial_labels = []\n",
    "    benign_images = []\n",
    "    benign_labels = []\n",
    "    check = 0\n",
    "    \n",
    "    num_iterations = 400\n",
    "    learning_rate = 0.01\n",
    "    check=0\n",
    "        \n",
    "    for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        #print(x_batch.shape)\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        images_adv,y_pred_adv = imagenet_make_cw_attack(x_batch, y_batch,normal_model, eps, conf, num_iterations, learning_rate)\n",
    "        images_adv, y_pred_adv = images_adv.to(device), y_pred_adv.to(device)\n",
    "        \n",
    "        check+=len(images_adv)\n",
    "        # Append adversarial images and labels to the batch\n",
    "        adversarial_images.append(images_adv.detach().cpu().numpy())\n",
    "        adversarial_labels.append(y_pred_adv.detach().cpu().numpy())\n",
    "        # Append benign images and labels to the batch\n",
    "        b_image, b_label = x_batch.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "        benign_images.append(b_image)\n",
    "        benign_labels.append(b_label)\n",
    "        \n",
    "        if (check)%50==0:\n",
    "            print((check)) \n",
    "            \n",
    "        if check > 1000:\n",
    "            break\n",
    "        \n",
    "    # Concatenate the batch of adversarial images and labels into NumPy arrays\n",
    "    adv_images = np.concatenate(adversarial_images)\n",
    "    adv_labels = np.concatenate(adversarial_labels)\n",
    "    ben_images = np.concatenate(benign_images)\n",
    "    ben_labels = np.concatenate(benign_labels)\n",
    "    \n",
    "    np.savez(os.path.join(save_dir, str(eps)+'eps.npz'), a_images=adv_images, a_labels=adv_labels, b_images=ben_images, b_labels=ben_labels)\n",
    "\n",
    "    \n",
    "    \n",
    "#launch attack\n",
    "confidence = [0]\n",
    "epsilons = 0.15\n",
    "save_dir = 'adv samples/IMAGENET/ResNet50/CW/'\n",
    "for conf in confidence: \n",
    "    compute_cw(test_loader, normal_model, epsilons, conf, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a982fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad718855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_detection",
   "language": "python",
   "name": "adv_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
